{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "view-in-github"
   },
   "source": [
    "<a href=\"https://colab.research.google.com/github/freddy-7/TI3002C/blob/main/9_Regresion_Logistica.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {
    "id": "38EWRjuebp99"
   },
   "outputs": [],
   "source": [
    "#Cargamos librerias\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import scipy.special as special\n",
    "from scipy.optimize import curve_fit\n",
    "import seaborn as sns\n",
    "from sklearn.metrics import r2_score\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler, LabelEncoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "id": "dUTL3f-ucVrR"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>host_name</th>\n",
       "      <th>host_since</th>\n",
       "      <th>host_response_time</th>\n",
       "      <th>property_type</th>\n",
       "      <th>room_type</th>\n",
       "      <th>bathrooms_text</th>\n",
       "      <th>first_review</th>\n",
       "      <th>last_review</th>\n",
       "      <th>host_response_rate</th>\n",
       "      <th>...</th>\n",
       "      <th>review_scores_value</th>\n",
       "      <th>instant_bookable</th>\n",
       "      <th>calculated_host_listings_count</th>\n",
       "      <th>calculated_host_listings_count_entire_homes</th>\n",
       "      <th>calculated_host_listings_count_private_rooms</th>\n",
       "      <th>calculated_host_listings_count_shared_rooms</th>\n",
       "      <th>reviews_per_month</th>\n",
       "      <th>host_since_num</th>\n",
       "      <th>first_review_num</th>\n",
       "      <th>last_review_num</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>Rita</td>\n",
       "      <td>26/11/2010</td>\n",
       "      <td>within a few hours</td>\n",
       "      <td>Entire condo</td>\n",
       "      <td>Entire home/apt</td>\n",
       "      <td>1 bath</td>\n",
       "      <td>29/12/2010</td>\n",
       "      <td>30/04/2025</td>\n",
       "      <td>1.0</td>\n",
       "      <td>...</td>\n",
       "      <td>4.78</td>\n",
       "      <td>0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.32</td>\n",
       "      <td>417</td>\n",
       "      <td>4827.0</td>\n",
       "      <td>3433.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>Michelle</td>\n",
       "      <td>19/11/2012</td>\n",
       "      <td>within an hour</td>\n",
       "      <td>Entire condo</td>\n",
       "      <td>Entire home/apt</td>\n",
       "      <td>1 bath</td>\n",
       "      <td>01/02/2013</td>\n",
       "      <td>27/07/2024</td>\n",
       "      <td>1.0</td>\n",
       "      <td>...</td>\n",
       "      <td>4.76</td>\n",
       "      <td>0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.46</td>\n",
       "      <td>1141</td>\n",
       "      <td>4827.0</td>\n",
       "      <td>3521.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>Judy</td>\n",
       "      <td>27/12/2012</td>\n",
       "      <td>within an hour</td>\n",
       "      <td>Private room in home</td>\n",
       "      <td>Private room</td>\n",
       "      <td>1 private bath</td>\n",
       "      <td>29/08/2016</td>\n",
       "      <td>30/09/2023</td>\n",
       "      <td>1.0</td>\n",
       "      <td>...</td>\n",
       "      <td>4.83</td>\n",
       "      <td>0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.66</td>\n",
       "      <td>1179</td>\n",
       "      <td>4827.0</td>\n",
       "      <td>3521.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>Joan</td>\n",
       "      <td>23/04/2013</td>\n",
       "      <td>within an hour</td>\n",
       "      <td>Entire rental unit</td>\n",
       "      <td>Entire home/apt</td>\n",
       "      <td>1 bath</td>\n",
       "      <td>02/06/2013</td>\n",
       "      <td>29/10/2024</td>\n",
       "      <td>1.0</td>\n",
       "      <td>...</td>\n",
       "      <td>4.66</td>\n",
       "      <td>1</td>\n",
       "      <td>9.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.65</td>\n",
       "      <td>1296</td>\n",
       "      <td>4827.0</td>\n",
       "      <td>3521.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>C. F. Sandy</td>\n",
       "      <td>13/06/2013</td>\n",
       "      <td>within a day</td>\n",
       "      <td>Private room in home</td>\n",
       "      <td>Private room</td>\n",
       "      <td>1 shared bath</td>\n",
       "      <td>23/04/2017</td>\n",
       "      <td>09/11/2019</td>\n",
       "      <td>1.0</td>\n",
       "      <td>...</td>\n",
       "      <td>4.53</td>\n",
       "      <td>0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.30</td>\n",
       "      <td>1347</td>\n",
       "      <td>4827.0</td>\n",
       "      <td>3521.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 53 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   Unnamed: 0    host_name  host_since  host_response_time  \\\n",
       "0           0         Rita  26/11/2010  within a few hours   \n",
       "1           1     Michelle  19/11/2012      within an hour   \n",
       "2           2         Judy  27/12/2012      within an hour   \n",
       "3           3         Joan  23/04/2013      within an hour   \n",
       "4           4  C. F. Sandy  13/06/2013        within a day   \n",
       "\n",
       "          property_type        room_type  bathrooms_text first_review  \\\n",
       "0          Entire condo  Entire home/apt          1 bath   29/12/2010   \n",
       "1          Entire condo  Entire home/apt          1 bath   01/02/2013   \n",
       "2  Private room in home     Private room  1 private bath   29/08/2016   \n",
       "3    Entire rental unit  Entire home/apt          1 bath   02/06/2013   \n",
       "4  Private room in home     Private room   1 shared bath   23/04/2017   \n",
       "\n",
       "  last_review  host_response_rate  ...  review_scores_value  instant_bookable  \\\n",
       "0  30/04/2025                 1.0  ...                 4.78                 0   \n",
       "1  27/07/2024                 1.0  ...                 4.76                 0   \n",
       "2  30/09/2023                 1.0  ...                 4.83                 0   \n",
       "3  29/10/2024                 1.0  ...                 4.66                 1   \n",
       "4  09/11/2019                 1.0  ...                 4.53                 0   \n",
       "\n",
       "   calculated_host_listings_count  \\\n",
       "0                             1.0   \n",
       "1                             1.0   \n",
       "2                             2.0   \n",
       "3                             9.0   \n",
       "4                             1.0   \n",
       "\n",
       "   calculated_host_listings_count_entire_homes  \\\n",
       "0                                          1.0   \n",
       "1                                          1.0   \n",
       "2                                          0.0   \n",
       "3                                          9.0   \n",
       "4                                          0.0   \n",
       "\n",
       "   calculated_host_listings_count_private_rooms  \\\n",
       "0                                           0.0   \n",
       "1                                           0.0   \n",
       "2                                           0.0   \n",
       "3                                           0.0   \n",
       "4                                           0.0   \n",
       "\n",
       "   calculated_host_listings_count_shared_rooms  reviews_per_month  \\\n",
       "0                                          0.0               0.32   \n",
       "1                                          0.0               0.46   \n",
       "2                                          0.0               0.66   \n",
       "3                                          0.0               0.65   \n",
       "4                                          0.0               0.30   \n",
       "\n",
       "   host_since_num  first_review_num  last_review_num  \n",
       "0             417            4827.0           3433.0  \n",
       "1            1141            4827.0           3521.0  \n",
       "2            1179            4827.0           3521.0  \n",
       "3            1296            4827.0           3521.0  \n",
       "4            1347            4827.0           3521.0  \n",
       "\n",
       "[5 rows x 53 columns]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv(\"Datos_limpios.csv\")\n",
    "df.head(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Instant_bookable"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Codificar la variable categórica room_type\n",
    "le = LabelEncoder()\n",
    "df['room_type_encoded'] = le.fit_transform(df['room_type'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "id": "UpTe1UuRcgnE"
   },
   "outputs": [],
   "source": [
    "#Declaramos las variables dependientes e independientes para la regresión Logística\n",
    "Vars_Indep= df[['host_response_rate', 'review_scores_value', 'room_type_encoded']]\n",
    "Var_Dep= df['instant_bookable']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "id": "wACjx4bAchca"
   },
   "outputs": [],
   "source": [
    "#Redefinimos las variables \n",
    "X= Vars_Indep\n",
    "y= Var_Dep"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "id": "0SlqN20_ckc5"
   },
   "outputs": [],
   "source": [
    "#Dividimos el conjunto de datos en la parte de entrenamiento y prueba:\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state =None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "id": "MkwSH7-1eZpR"
   },
   "outputs": [],
   "source": [
    "#Se escalan todos los datos\n",
    "escalar = StandardScaler()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "id": "m7G55cbNefKi"
   },
   "outputs": [],
   "source": [
    "#Para realizar el escalamiento de las variables “X” tanto de entrenamiento como de prueba, utilizaremos fit_transform\n",
    "X_train = escalar.fit_transform(X_train)\n",
    "X_test = escalar.transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "id": "9ODFuBepehxE"
   },
   "outputs": [],
   "source": [
    "#Definimos el algoritmo a utilizar\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "algoritmo = LogisticRegression()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 74
    },
    "id": "TGoNkF8eej4u",
    "outputId": "62b8f1db-c496-492c-b0f2-96688eafc28d"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-1 {\n",
       "  /* Definition of color scheme common for light and dark mode */\n",
       "  --sklearn-color-text: black;\n",
       "  --sklearn-color-line: gray;\n",
       "  /* Definition of color scheme for unfitted estimators */\n",
       "  --sklearn-color-unfitted-level-0: #fff5e6;\n",
       "  --sklearn-color-unfitted-level-1: #f6e4d2;\n",
       "  --sklearn-color-unfitted-level-2: #ffe0b3;\n",
       "  --sklearn-color-unfitted-level-3: chocolate;\n",
       "  /* Definition of color scheme for fitted estimators */\n",
       "  --sklearn-color-fitted-level-0: #f0f8ff;\n",
       "  --sklearn-color-fitted-level-1: #d4ebff;\n",
       "  --sklearn-color-fitted-level-2: #b3dbfd;\n",
       "  --sklearn-color-fitted-level-3: cornflowerblue;\n",
       "\n",
       "  /* Specific color for light theme */\n",
       "  --sklearn-color-text-on-default-background: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, black)));\n",
       "  --sklearn-color-background: var(--sg-background-color, var(--theme-background, var(--jp-layout-color0, white)));\n",
       "  --sklearn-color-border-box: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, black)));\n",
       "  --sklearn-color-icon: #696969;\n",
       "\n",
       "  @media (prefers-color-scheme: dark) {\n",
       "    /* Redefinition of color scheme for dark theme */\n",
       "    --sklearn-color-text-on-default-background: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, white)));\n",
       "    --sklearn-color-background: var(--sg-background-color, var(--theme-background, var(--jp-layout-color0, #111)));\n",
       "    --sklearn-color-border-box: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, white)));\n",
       "    --sklearn-color-icon: #878787;\n",
       "  }\n",
       "}\n",
       "\n",
       "#sk-container-id-1 {\n",
       "  color: var(--sklearn-color-text);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 pre {\n",
       "  padding: 0;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 input.sk-hidden--visually {\n",
       "  border: 0;\n",
       "  clip: rect(1px 1px 1px 1px);\n",
       "  clip: rect(1px, 1px, 1px, 1px);\n",
       "  height: 1px;\n",
       "  margin: -1px;\n",
       "  overflow: hidden;\n",
       "  padding: 0;\n",
       "  position: absolute;\n",
       "  width: 1px;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-dashed-wrapped {\n",
       "  border: 1px dashed var(--sklearn-color-line);\n",
       "  margin: 0 0.4em 0.5em 0.4em;\n",
       "  box-sizing: border-box;\n",
       "  padding-bottom: 0.4em;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-container {\n",
       "  /* jupyter's `normalize.less` sets `[hidden] { display: none; }`\n",
       "     but bootstrap.min.css set `[hidden] { display: none !important; }`\n",
       "     so we also need the `!important` here to be able to override the\n",
       "     default hidden behavior on the sphinx rendered scikit-learn.org.\n",
       "     See: https://github.com/scikit-learn/scikit-learn/issues/21755 */\n",
       "  display: inline-block !important;\n",
       "  position: relative;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-text-repr-fallback {\n",
       "  display: none;\n",
       "}\n",
       "\n",
       "div.sk-parallel-item,\n",
       "div.sk-serial,\n",
       "div.sk-item {\n",
       "  /* draw centered vertical line to link estimators */\n",
       "  background-image: linear-gradient(var(--sklearn-color-text-on-default-background), var(--sklearn-color-text-on-default-background));\n",
       "  background-size: 2px 100%;\n",
       "  background-repeat: no-repeat;\n",
       "  background-position: center center;\n",
       "}\n",
       "\n",
       "/* Parallel-specific style estimator block */\n",
       "\n",
       "#sk-container-id-1 div.sk-parallel-item::after {\n",
       "  content: \"\";\n",
       "  width: 100%;\n",
       "  border-bottom: 2px solid var(--sklearn-color-text-on-default-background);\n",
       "  flex-grow: 1;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-parallel {\n",
       "  display: flex;\n",
       "  align-items: stretch;\n",
       "  justify-content: center;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "  position: relative;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-parallel-item {\n",
       "  display: flex;\n",
       "  flex-direction: column;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-parallel-item:first-child::after {\n",
       "  align-self: flex-end;\n",
       "  width: 50%;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-parallel-item:last-child::after {\n",
       "  align-self: flex-start;\n",
       "  width: 50%;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-parallel-item:only-child::after {\n",
       "  width: 0;\n",
       "}\n",
       "\n",
       "/* Serial-specific style estimator block */\n",
       "\n",
       "#sk-container-id-1 div.sk-serial {\n",
       "  display: flex;\n",
       "  flex-direction: column;\n",
       "  align-items: center;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "  padding-right: 1em;\n",
       "  padding-left: 1em;\n",
       "}\n",
       "\n",
       "\n",
       "/* Toggleable style: style used for estimator/Pipeline/ColumnTransformer box that is\n",
       "clickable and can be expanded/collapsed.\n",
       "- Pipeline and ColumnTransformer use this feature and define the default style\n",
       "- Estimators will overwrite some part of the style using the `sk-estimator` class\n",
       "*/\n",
       "\n",
       "/* Pipeline and ColumnTransformer style (default) */\n",
       "\n",
       "#sk-container-id-1 div.sk-toggleable {\n",
       "  /* Default theme specific background. It is overwritten whether we have a\n",
       "  specific estimator or a Pipeline/ColumnTransformer */\n",
       "  background-color: var(--sklearn-color-background);\n",
       "}\n",
       "\n",
       "/* Toggleable label */\n",
       "#sk-container-id-1 label.sk-toggleable__label {\n",
       "  cursor: pointer;\n",
       "  display: block;\n",
       "  width: 100%;\n",
       "  margin-bottom: 0;\n",
       "  padding: 0.5em;\n",
       "  box-sizing: border-box;\n",
       "  text-align: center;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 label.sk-toggleable__label-arrow:before {\n",
       "  /* Arrow on the left of the label */\n",
       "  content: \"▸\";\n",
       "  float: left;\n",
       "  margin-right: 0.25em;\n",
       "  color: var(--sklearn-color-icon);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 label.sk-toggleable__label-arrow:hover:before {\n",
       "  color: var(--sklearn-color-text);\n",
       "}\n",
       "\n",
       "/* Toggleable content - dropdown */\n",
       "\n",
       "#sk-container-id-1 div.sk-toggleable__content {\n",
       "  max-height: 0;\n",
       "  max-width: 0;\n",
       "  overflow: hidden;\n",
       "  text-align: left;\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-toggleable__content.fitted {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-toggleable__content pre {\n",
       "  margin: 0.2em;\n",
       "  border-radius: 0.25em;\n",
       "  color: var(--sklearn-color-text);\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-toggleable__content.fitted pre {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 input.sk-toggleable__control:checked~div.sk-toggleable__content {\n",
       "  /* Expand drop-down */\n",
       "  max-height: 200px;\n",
       "  max-width: 100%;\n",
       "  overflow: auto;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {\n",
       "  content: \"▾\";\n",
       "}\n",
       "\n",
       "/* Pipeline/ColumnTransformer-specific style */\n",
       "\n",
       "#sk-container-id-1 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
       "  color: var(--sklearn-color-text);\n",
       "  background-color: var(--sklearn-color-unfitted-level-2);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-label.fitted input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
       "  background-color: var(--sklearn-color-fitted-level-2);\n",
       "}\n",
       "\n",
       "/* Estimator-specific style */\n",
       "\n",
       "/* Colorize estimator box */\n",
       "#sk-container-id-1 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-2);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-estimator.fitted input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-2);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-label label.sk-toggleable__label,\n",
       "#sk-container-id-1 div.sk-label label {\n",
       "  /* The background is the default theme color */\n",
       "  color: var(--sklearn-color-text-on-default-background);\n",
       "}\n",
       "\n",
       "/* On hover, darken the color of the background */\n",
       "#sk-container-id-1 div.sk-label:hover label.sk-toggleable__label {\n",
       "  color: var(--sklearn-color-text);\n",
       "  background-color: var(--sklearn-color-unfitted-level-2);\n",
       "}\n",
       "\n",
       "/* Label box, darken color on hover, fitted */\n",
       "#sk-container-id-1 div.sk-label.fitted:hover label.sk-toggleable__label.fitted {\n",
       "  color: var(--sklearn-color-text);\n",
       "  background-color: var(--sklearn-color-fitted-level-2);\n",
       "}\n",
       "\n",
       "/* Estimator label */\n",
       "\n",
       "#sk-container-id-1 div.sk-label label {\n",
       "  font-family: monospace;\n",
       "  font-weight: bold;\n",
       "  display: inline-block;\n",
       "  line-height: 1.2em;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-label-container {\n",
       "  text-align: center;\n",
       "}\n",
       "\n",
       "/* Estimator-specific */\n",
       "#sk-container-id-1 div.sk-estimator {\n",
       "  font-family: monospace;\n",
       "  border: 1px dotted var(--sklearn-color-border-box);\n",
       "  border-radius: 0.25em;\n",
       "  box-sizing: border-box;\n",
       "  margin-bottom: 0.5em;\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-estimator.fitted {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-0);\n",
       "}\n",
       "\n",
       "/* on hover */\n",
       "#sk-container-id-1 div.sk-estimator:hover {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-2);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-estimator.fitted:hover {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-2);\n",
       "}\n",
       "\n",
       "/* Specification for estimator info (e.g. \"i\" and \"?\") */\n",
       "\n",
       "/* Common style for \"i\" and \"?\" */\n",
       "\n",
       ".sk-estimator-doc-link,\n",
       "a:link.sk-estimator-doc-link,\n",
       "a:visited.sk-estimator-doc-link {\n",
       "  float: right;\n",
       "  font-size: smaller;\n",
       "  line-height: 1em;\n",
       "  font-family: monospace;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "  border-radius: 1em;\n",
       "  height: 1em;\n",
       "  width: 1em;\n",
       "  text-decoration: none !important;\n",
       "  margin-left: 1ex;\n",
       "  /* unfitted */\n",
       "  border: var(--sklearn-color-unfitted-level-1) 1pt solid;\n",
       "  color: var(--sklearn-color-unfitted-level-1);\n",
       "}\n",
       "\n",
       ".sk-estimator-doc-link.fitted,\n",
       "a:link.sk-estimator-doc-link.fitted,\n",
       "a:visited.sk-estimator-doc-link.fitted {\n",
       "  /* fitted */\n",
       "  border: var(--sklearn-color-fitted-level-1) 1pt solid;\n",
       "  color: var(--sklearn-color-fitted-level-1);\n",
       "}\n",
       "\n",
       "/* On hover */\n",
       "div.sk-estimator:hover .sk-estimator-doc-link:hover,\n",
       ".sk-estimator-doc-link:hover,\n",
       "div.sk-label-container:hover .sk-estimator-doc-link:hover,\n",
       ".sk-estimator-doc-link:hover {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-3);\n",
       "  color: var(--sklearn-color-background);\n",
       "  text-decoration: none;\n",
       "}\n",
       "\n",
       "div.sk-estimator.fitted:hover .sk-estimator-doc-link.fitted:hover,\n",
       ".sk-estimator-doc-link.fitted:hover,\n",
       "div.sk-label-container:hover .sk-estimator-doc-link.fitted:hover,\n",
       ".sk-estimator-doc-link.fitted:hover {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-3);\n",
       "  color: var(--sklearn-color-background);\n",
       "  text-decoration: none;\n",
       "}\n",
       "\n",
       "/* Span, style for the box shown on hovering the info icon */\n",
       ".sk-estimator-doc-link span {\n",
       "  display: none;\n",
       "  z-index: 9999;\n",
       "  position: relative;\n",
       "  font-weight: normal;\n",
       "  right: .2ex;\n",
       "  padding: .5ex;\n",
       "  margin: .5ex;\n",
       "  width: min-content;\n",
       "  min-width: 20ex;\n",
       "  max-width: 50ex;\n",
       "  color: var(--sklearn-color-text);\n",
       "  box-shadow: 2pt 2pt 4pt #999;\n",
       "  /* unfitted */\n",
       "  background: var(--sklearn-color-unfitted-level-0);\n",
       "  border: .5pt solid var(--sklearn-color-unfitted-level-3);\n",
       "}\n",
       "\n",
       ".sk-estimator-doc-link.fitted span {\n",
       "  /* fitted */\n",
       "  background: var(--sklearn-color-fitted-level-0);\n",
       "  border: var(--sklearn-color-fitted-level-3);\n",
       "}\n",
       "\n",
       ".sk-estimator-doc-link:hover span {\n",
       "  display: block;\n",
       "}\n",
       "\n",
       "/* \"?\"-specific style due to the `<a>` HTML tag */\n",
       "\n",
       "#sk-container-id-1 a.estimator_doc_link {\n",
       "  float: right;\n",
       "  font-size: 1rem;\n",
       "  line-height: 1em;\n",
       "  font-family: monospace;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "  border-radius: 1rem;\n",
       "  height: 1rem;\n",
       "  width: 1rem;\n",
       "  text-decoration: none;\n",
       "  /* unfitted */\n",
       "  color: var(--sklearn-color-unfitted-level-1);\n",
       "  border: var(--sklearn-color-unfitted-level-1) 1pt solid;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 a.estimator_doc_link.fitted {\n",
       "  /* fitted */\n",
       "  border: var(--sklearn-color-fitted-level-1) 1pt solid;\n",
       "  color: var(--sklearn-color-fitted-level-1);\n",
       "}\n",
       "\n",
       "/* On hover */\n",
       "#sk-container-id-1 a.estimator_doc_link:hover {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-3);\n",
       "  color: var(--sklearn-color-background);\n",
       "  text-decoration: none;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 a.estimator_doc_link.fitted:hover {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-3);\n",
       "}\n",
       "</style><div id=\"sk-container-id-1\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>LogisticRegression()</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator fitted sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-1\" type=\"checkbox\" checked><label for=\"sk-estimator-id-1\" class=\"sk-toggleable__label fitted sk-toggleable__label-arrow fitted\">&nbsp;&nbsp;LogisticRegression<a class=\"sk-estimator-doc-link fitted\" rel=\"noreferrer\" target=\"_blank\" href=\"https://scikit-learn.org/1.5/modules/generated/sklearn.linear_model.LogisticRegression.html\">?<span>Documentation for LogisticRegression</span></a><span class=\"sk-estimator-doc-link fitted\">i<span>Fitted</span></span></label><div class=\"sk-toggleable__content fitted\"><pre>LogisticRegression()</pre></div> </div></div></div></div>"
      ],
      "text/plain": [
       "LogisticRegression()"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Entrenamos el modelo\n",
    "algoritmo.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "id": "RmhkpqPufPtq"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0, 0, 0, ..., 1, 0, 0], dtype=int64)"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Realizamos una predicción\n",
    "y_pred = algoritmo.predict(X_test) \n",
    "y_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Valores únicos en y_test: [0 1]\n",
      "Valores únicos en y_pred: [0 1]\n"
     ]
    }
   ],
   "source": [
    "# Verificar los valores únicos en y_test y y_pred\n",
    "print(\"Valores únicos en y_test:\", np.unique(y_test))\n",
    "print(\"Valores únicos en y_pred:\", np.unique(y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "HcmoerMWfSgz",
    "outputId": "7da3acbc-b662-481a-bc38-97ea22b4120b"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Matriz de Confusión:\n",
      "[[959  62]\n",
      " [545 151]]\n"
     ]
    }
   ],
   "source": [
    "#Verifico la matriz de Confusión\n",
    "from sklearn.metrics import confusion_matrix\n",
    "matriz = confusion_matrix(y_test, y_pred)\n",
    "print('Matriz de Confusión:')\n",
    "print(matriz)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "EZLYhQv9ffsZ",
    "outputId": "2775444d-1f00-4371-8433-a5bf75e26113"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Precisión del modelo F:\n",
      "0.6376329787234043\n"
     ]
    }
   ],
   "source": [
    "#Calculo la precisión del modelo Yes=1 No=0\n",
    "from sklearn.metrics import precision_score\n",
    "\n",
    "precision = precision_score(y_test, y_pred, average=\"binary\", pos_label=0)\n",
    "print('Precisión del modelo F:')\n",
    "print(precision)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Precisión del modelo T:\n",
      "0.7089201877934272\n"
     ]
    }
   ],
   "source": [
    "#Calculo la precisión del modelo\n",
    "from sklearn.metrics import precision_score\n",
    "\n",
    "precision = precision_score(y_test, y_pred, average=\"binary\", pos_label=1)\n",
    "print('Precisión del modelo T:')\n",
    "print(precision)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "JuQmoNf8gPHT",
    "outputId": "362da694-2ed2-4416-aecd-a34c6843946b"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Exactitud del modelo:\n",
      "0.6464764123471171\n"
     ]
    }
   ],
   "source": [
    "#Calculo la exactitud del modelo\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "exactitud = accuracy_score(y_test, y_pred)\n",
    "print('Exactitud del modelo:')\n",
    "print(exactitud)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "2ROKMocYgRNb",
    "outputId": "b9cfe0a3-7b49-436c-e90e-4f69f90024e4"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sensibilidad del modelo F:\n",
      "0.9392752203721841\n"
     ]
    }
   ],
   "source": [
    "#Calculo la sensibilidad del modelo yes=1 No=0\n",
    "from sklearn.metrics import recall_score\n",
    "\n",
    "sensibilidad = recall_score(y_test, y_pred, average=\"binary\", pos_label=0)\n",
    "print('Sensibilidad del modelo F:')\n",
    "print(sensibilidad)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sensibilidad del modelo T:\n",
      "0.21695402298850575\n"
     ]
    }
   ],
   "source": [
    "#Calculo la sensibilidad del modelo\n",
    "from sklearn.metrics import recall_score\n",
    "\n",
    "sensibilidad = recall_score(y_test, y_pred, average=\"binary\", pos_label=1)\n",
    "print('Sensibilidad del modelo T:')\n",
    "print(sensibilidad)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "dpVw7tZ1gUja",
    "outputId": "bf6f3b49-3e02-40a9-e7cc-22e4d9d73e9c"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Puntaje F1 del modelo:\n",
      "0.33223322332233224\n"
     ]
    }
   ],
   "source": [
    "# el puntaje F1 que es una combinación entre la precisión y la sensibilidad, para esto importamos f1_score.\n",
    "#Calculo el Puntaje F1 del modelo\n",
    "from sklearn.metrics import f1_score\n",
    "\n",
    "puntajef1 = f1_score(y_test, y_pred, average=\"binary\", pos_label=1)\n",
    "print('Puntaje F1 del modelo:')\n",
    "print(puntajef1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "host_is_superhost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Declaramos las variables dependientes e independientes para la regresión Logística\n",
    "Vars_Indep = df[['host_response_rate', 'review_scores_rating', 'review_scores_cleanliness', \n",
    "                 'review_scores_communication', 'number_of_reviews']]\n",
    "Var_Dep = df['host_is_superhost']\n",
    "\n",
    "#Redefinimos las variables \n",
    "X = Vars_Indep\n",
    "y = Var_Dep\n",
    "\n",
    "#Dividimos el conjunto de datos en la parte de entrenamiento y prueba:\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Se escalan todos los datos\n",
    "escalar = StandardScaler()\n",
    "\n",
    "#Para realizar el escalamiento de las variables “X” tanto de entrenamiento como de prueba, utilizaremos fit_transform\n",
    "X_train = escalar.fit_transform(X_train)\n",
    "X_test = escalar.transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-2 {\n",
       "  /* Definition of color scheme common for light and dark mode */\n",
       "  --sklearn-color-text: black;\n",
       "  --sklearn-color-line: gray;\n",
       "  /* Definition of color scheme for unfitted estimators */\n",
       "  --sklearn-color-unfitted-level-0: #fff5e6;\n",
       "  --sklearn-color-unfitted-level-1: #f6e4d2;\n",
       "  --sklearn-color-unfitted-level-2: #ffe0b3;\n",
       "  --sklearn-color-unfitted-level-3: chocolate;\n",
       "  /* Definition of color scheme for fitted estimators */\n",
       "  --sklearn-color-fitted-level-0: #f0f8ff;\n",
       "  --sklearn-color-fitted-level-1: #d4ebff;\n",
       "  --sklearn-color-fitted-level-2: #b3dbfd;\n",
       "  --sklearn-color-fitted-level-3: cornflowerblue;\n",
       "\n",
       "  /* Specific color for light theme */\n",
       "  --sklearn-color-text-on-default-background: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, black)));\n",
       "  --sklearn-color-background: var(--sg-background-color, var(--theme-background, var(--jp-layout-color0, white)));\n",
       "  --sklearn-color-border-box: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, black)));\n",
       "  --sklearn-color-icon: #696969;\n",
       "\n",
       "  @media (prefers-color-scheme: dark) {\n",
       "    /* Redefinition of color scheme for dark theme */\n",
       "    --sklearn-color-text-on-default-background: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, white)));\n",
       "    --sklearn-color-background: var(--sg-background-color, var(--theme-background, var(--jp-layout-color0, #111)));\n",
       "    --sklearn-color-border-box: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, white)));\n",
       "    --sklearn-color-icon: #878787;\n",
       "  }\n",
       "}\n",
       "\n",
       "#sk-container-id-2 {\n",
       "  color: var(--sklearn-color-text);\n",
       "}\n",
       "\n",
       "#sk-container-id-2 pre {\n",
       "  padding: 0;\n",
       "}\n",
       "\n",
       "#sk-container-id-2 input.sk-hidden--visually {\n",
       "  border: 0;\n",
       "  clip: rect(1px 1px 1px 1px);\n",
       "  clip: rect(1px, 1px, 1px, 1px);\n",
       "  height: 1px;\n",
       "  margin: -1px;\n",
       "  overflow: hidden;\n",
       "  padding: 0;\n",
       "  position: absolute;\n",
       "  width: 1px;\n",
       "}\n",
       "\n",
       "#sk-container-id-2 div.sk-dashed-wrapped {\n",
       "  border: 1px dashed var(--sklearn-color-line);\n",
       "  margin: 0 0.4em 0.5em 0.4em;\n",
       "  box-sizing: border-box;\n",
       "  padding-bottom: 0.4em;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "}\n",
       "\n",
       "#sk-container-id-2 div.sk-container {\n",
       "  /* jupyter's `normalize.less` sets `[hidden] { display: none; }`\n",
       "     but bootstrap.min.css set `[hidden] { display: none !important; }`\n",
       "     so we also need the `!important` here to be able to override the\n",
       "     default hidden behavior on the sphinx rendered scikit-learn.org.\n",
       "     See: https://github.com/scikit-learn/scikit-learn/issues/21755 */\n",
       "  display: inline-block !important;\n",
       "  position: relative;\n",
       "}\n",
       "\n",
       "#sk-container-id-2 div.sk-text-repr-fallback {\n",
       "  display: none;\n",
       "}\n",
       "\n",
       "div.sk-parallel-item,\n",
       "div.sk-serial,\n",
       "div.sk-item {\n",
       "  /* draw centered vertical line to link estimators */\n",
       "  background-image: linear-gradient(var(--sklearn-color-text-on-default-background), var(--sklearn-color-text-on-default-background));\n",
       "  background-size: 2px 100%;\n",
       "  background-repeat: no-repeat;\n",
       "  background-position: center center;\n",
       "}\n",
       "\n",
       "/* Parallel-specific style estimator block */\n",
       "\n",
       "#sk-container-id-2 div.sk-parallel-item::after {\n",
       "  content: \"\";\n",
       "  width: 100%;\n",
       "  border-bottom: 2px solid var(--sklearn-color-text-on-default-background);\n",
       "  flex-grow: 1;\n",
       "}\n",
       "\n",
       "#sk-container-id-2 div.sk-parallel {\n",
       "  display: flex;\n",
       "  align-items: stretch;\n",
       "  justify-content: center;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "  position: relative;\n",
       "}\n",
       "\n",
       "#sk-container-id-2 div.sk-parallel-item {\n",
       "  display: flex;\n",
       "  flex-direction: column;\n",
       "}\n",
       "\n",
       "#sk-container-id-2 div.sk-parallel-item:first-child::after {\n",
       "  align-self: flex-end;\n",
       "  width: 50%;\n",
       "}\n",
       "\n",
       "#sk-container-id-2 div.sk-parallel-item:last-child::after {\n",
       "  align-self: flex-start;\n",
       "  width: 50%;\n",
       "}\n",
       "\n",
       "#sk-container-id-2 div.sk-parallel-item:only-child::after {\n",
       "  width: 0;\n",
       "}\n",
       "\n",
       "/* Serial-specific style estimator block */\n",
       "\n",
       "#sk-container-id-2 div.sk-serial {\n",
       "  display: flex;\n",
       "  flex-direction: column;\n",
       "  align-items: center;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "  padding-right: 1em;\n",
       "  padding-left: 1em;\n",
       "}\n",
       "\n",
       "\n",
       "/* Toggleable style: style used for estimator/Pipeline/ColumnTransformer box that is\n",
       "clickable and can be expanded/collapsed.\n",
       "- Pipeline and ColumnTransformer use this feature and define the default style\n",
       "- Estimators will overwrite some part of the style using the `sk-estimator` class\n",
       "*/\n",
       "\n",
       "/* Pipeline and ColumnTransformer style (default) */\n",
       "\n",
       "#sk-container-id-2 div.sk-toggleable {\n",
       "  /* Default theme specific background. It is overwritten whether we have a\n",
       "  specific estimator or a Pipeline/ColumnTransformer */\n",
       "  background-color: var(--sklearn-color-background);\n",
       "}\n",
       "\n",
       "/* Toggleable label */\n",
       "#sk-container-id-2 label.sk-toggleable__label {\n",
       "  cursor: pointer;\n",
       "  display: block;\n",
       "  width: 100%;\n",
       "  margin-bottom: 0;\n",
       "  padding: 0.5em;\n",
       "  box-sizing: border-box;\n",
       "  text-align: center;\n",
       "}\n",
       "\n",
       "#sk-container-id-2 label.sk-toggleable__label-arrow:before {\n",
       "  /* Arrow on the left of the label */\n",
       "  content: \"▸\";\n",
       "  float: left;\n",
       "  margin-right: 0.25em;\n",
       "  color: var(--sklearn-color-icon);\n",
       "}\n",
       "\n",
       "#sk-container-id-2 label.sk-toggleable__label-arrow:hover:before {\n",
       "  color: var(--sklearn-color-text);\n",
       "}\n",
       "\n",
       "/* Toggleable content - dropdown */\n",
       "\n",
       "#sk-container-id-2 div.sk-toggleable__content {\n",
       "  max-height: 0;\n",
       "  max-width: 0;\n",
       "  overflow: hidden;\n",
       "  text-align: left;\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-2 div.sk-toggleable__content.fitted {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-2 div.sk-toggleable__content pre {\n",
       "  margin: 0.2em;\n",
       "  border-radius: 0.25em;\n",
       "  color: var(--sklearn-color-text);\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-2 div.sk-toggleable__content.fitted pre {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-2 input.sk-toggleable__control:checked~div.sk-toggleable__content {\n",
       "  /* Expand drop-down */\n",
       "  max-height: 200px;\n",
       "  max-width: 100%;\n",
       "  overflow: auto;\n",
       "}\n",
       "\n",
       "#sk-container-id-2 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {\n",
       "  content: \"▾\";\n",
       "}\n",
       "\n",
       "/* Pipeline/ColumnTransformer-specific style */\n",
       "\n",
       "#sk-container-id-2 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
       "  color: var(--sklearn-color-text);\n",
       "  background-color: var(--sklearn-color-unfitted-level-2);\n",
       "}\n",
       "\n",
       "#sk-container-id-2 div.sk-label.fitted input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
       "  background-color: var(--sklearn-color-fitted-level-2);\n",
       "}\n",
       "\n",
       "/* Estimator-specific style */\n",
       "\n",
       "/* Colorize estimator box */\n",
       "#sk-container-id-2 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-2);\n",
       "}\n",
       "\n",
       "#sk-container-id-2 div.sk-estimator.fitted input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-2);\n",
       "}\n",
       "\n",
       "#sk-container-id-2 div.sk-label label.sk-toggleable__label,\n",
       "#sk-container-id-2 div.sk-label label {\n",
       "  /* The background is the default theme color */\n",
       "  color: var(--sklearn-color-text-on-default-background);\n",
       "}\n",
       "\n",
       "/* On hover, darken the color of the background */\n",
       "#sk-container-id-2 div.sk-label:hover label.sk-toggleable__label {\n",
       "  color: var(--sklearn-color-text);\n",
       "  background-color: var(--sklearn-color-unfitted-level-2);\n",
       "}\n",
       "\n",
       "/* Label box, darken color on hover, fitted */\n",
       "#sk-container-id-2 div.sk-label.fitted:hover label.sk-toggleable__label.fitted {\n",
       "  color: var(--sklearn-color-text);\n",
       "  background-color: var(--sklearn-color-fitted-level-2);\n",
       "}\n",
       "\n",
       "/* Estimator label */\n",
       "\n",
       "#sk-container-id-2 div.sk-label label {\n",
       "  font-family: monospace;\n",
       "  font-weight: bold;\n",
       "  display: inline-block;\n",
       "  line-height: 1.2em;\n",
       "}\n",
       "\n",
       "#sk-container-id-2 div.sk-label-container {\n",
       "  text-align: center;\n",
       "}\n",
       "\n",
       "/* Estimator-specific */\n",
       "#sk-container-id-2 div.sk-estimator {\n",
       "  font-family: monospace;\n",
       "  border: 1px dotted var(--sklearn-color-border-box);\n",
       "  border-radius: 0.25em;\n",
       "  box-sizing: border-box;\n",
       "  margin-bottom: 0.5em;\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-2 div.sk-estimator.fitted {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-0);\n",
       "}\n",
       "\n",
       "/* on hover */\n",
       "#sk-container-id-2 div.sk-estimator:hover {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-2);\n",
       "}\n",
       "\n",
       "#sk-container-id-2 div.sk-estimator.fitted:hover {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-2);\n",
       "}\n",
       "\n",
       "/* Specification for estimator info (e.g. \"i\" and \"?\") */\n",
       "\n",
       "/* Common style for \"i\" and \"?\" */\n",
       "\n",
       ".sk-estimator-doc-link,\n",
       "a:link.sk-estimator-doc-link,\n",
       "a:visited.sk-estimator-doc-link {\n",
       "  float: right;\n",
       "  font-size: smaller;\n",
       "  line-height: 1em;\n",
       "  font-family: monospace;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "  border-radius: 1em;\n",
       "  height: 1em;\n",
       "  width: 1em;\n",
       "  text-decoration: none !important;\n",
       "  margin-left: 1ex;\n",
       "  /* unfitted */\n",
       "  border: var(--sklearn-color-unfitted-level-1) 1pt solid;\n",
       "  color: var(--sklearn-color-unfitted-level-1);\n",
       "}\n",
       "\n",
       ".sk-estimator-doc-link.fitted,\n",
       "a:link.sk-estimator-doc-link.fitted,\n",
       "a:visited.sk-estimator-doc-link.fitted {\n",
       "  /* fitted */\n",
       "  border: var(--sklearn-color-fitted-level-1) 1pt solid;\n",
       "  color: var(--sklearn-color-fitted-level-1);\n",
       "}\n",
       "\n",
       "/* On hover */\n",
       "div.sk-estimator:hover .sk-estimator-doc-link:hover,\n",
       ".sk-estimator-doc-link:hover,\n",
       "div.sk-label-container:hover .sk-estimator-doc-link:hover,\n",
       ".sk-estimator-doc-link:hover {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-3);\n",
       "  color: var(--sklearn-color-background);\n",
       "  text-decoration: none;\n",
       "}\n",
       "\n",
       "div.sk-estimator.fitted:hover .sk-estimator-doc-link.fitted:hover,\n",
       ".sk-estimator-doc-link.fitted:hover,\n",
       "div.sk-label-container:hover .sk-estimator-doc-link.fitted:hover,\n",
       ".sk-estimator-doc-link.fitted:hover {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-3);\n",
       "  color: var(--sklearn-color-background);\n",
       "  text-decoration: none;\n",
       "}\n",
       "\n",
       "/* Span, style for the box shown on hovering the info icon */\n",
       ".sk-estimator-doc-link span {\n",
       "  display: none;\n",
       "  z-index: 9999;\n",
       "  position: relative;\n",
       "  font-weight: normal;\n",
       "  right: .2ex;\n",
       "  padding: .5ex;\n",
       "  margin: .5ex;\n",
       "  width: min-content;\n",
       "  min-width: 20ex;\n",
       "  max-width: 50ex;\n",
       "  color: var(--sklearn-color-text);\n",
       "  box-shadow: 2pt 2pt 4pt #999;\n",
       "  /* unfitted */\n",
       "  background: var(--sklearn-color-unfitted-level-0);\n",
       "  border: .5pt solid var(--sklearn-color-unfitted-level-3);\n",
       "}\n",
       "\n",
       ".sk-estimator-doc-link.fitted span {\n",
       "  /* fitted */\n",
       "  background: var(--sklearn-color-fitted-level-0);\n",
       "  border: var(--sklearn-color-fitted-level-3);\n",
       "}\n",
       "\n",
       ".sk-estimator-doc-link:hover span {\n",
       "  display: block;\n",
       "}\n",
       "\n",
       "/* \"?\"-specific style due to the `<a>` HTML tag */\n",
       "\n",
       "#sk-container-id-2 a.estimator_doc_link {\n",
       "  float: right;\n",
       "  font-size: 1rem;\n",
       "  line-height: 1em;\n",
       "  font-family: monospace;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "  border-radius: 1rem;\n",
       "  height: 1rem;\n",
       "  width: 1rem;\n",
       "  text-decoration: none;\n",
       "  /* unfitted */\n",
       "  color: var(--sklearn-color-unfitted-level-1);\n",
       "  border: var(--sklearn-color-unfitted-level-1) 1pt solid;\n",
       "}\n",
       "\n",
       "#sk-container-id-2 a.estimator_doc_link.fitted {\n",
       "  /* fitted */\n",
       "  border: var(--sklearn-color-fitted-level-1) 1pt solid;\n",
       "  color: var(--sklearn-color-fitted-level-1);\n",
       "}\n",
       "\n",
       "/* On hover */\n",
       "#sk-container-id-2 a.estimator_doc_link:hover {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-3);\n",
       "  color: var(--sklearn-color-background);\n",
       "  text-decoration: none;\n",
       "}\n",
       "\n",
       "#sk-container-id-2 a.estimator_doc_link.fitted:hover {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-3);\n",
       "}\n",
       "</style><div id=\"sk-container-id-2\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>LogisticRegression()</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator fitted sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-2\" type=\"checkbox\" checked><label for=\"sk-estimator-id-2\" class=\"sk-toggleable__label fitted sk-toggleable__label-arrow fitted\">&nbsp;&nbsp;LogisticRegression<a class=\"sk-estimator-doc-link fitted\" rel=\"noreferrer\" target=\"_blank\" href=\"https://scikit-learn.org/1.5/modules/generated/sklearn.linear_model.LogisticRegression.html\">?<span>Documentation for LogisticRegression</span></a><span class=\"sk-estimator-doc-link fitted\">i<span>Fitted</span></span></label><div class=\"sk-toggleable__content fitted\"><pre>LogisticRegression()</pre></div> </div></div></div></div>"
      ],
      "text/plain": [
       "LogisticRegression()"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Definimos el algoritmo a utilizar\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "algoritmo = LogisticRegression()\n",
    "\n",
    "#Entrenamos el modelo\n",
    "algoritmo.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Valores únicos en y_test: [0 1]\n",
      "Valores únicos en y_pred: [0 1]\n"
     ]
    }
   ],
   "source": [
    "#Realizamos una predicción\n",
    "y_pred = algoritmo.predict(X_test) \n",
    "y_pred\n",
    "\n",
    "# Verificar los valores únicos en y_test y y_pred\n",
    "print(\"Valores únicos en y_test:\", np.unique(y_test))\n",
    "print(\"Valores únicos en y_pred:\", np.unique(y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Matriz de Confusión:\n",
      "[[714 288]\n",
      " [259 456]]\n"
     ]
    }
   ],
   "source": [
    "#Verifico la matriz de Confusión\n",
    "from sklearn.metrics import confusion_matrix\n",
    "matriz = confusion_matrix(y_test, y_pred)\n",
    "print('Matriz de Confusión:')\n",
    "print(matriz)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Precisión del modelo T:\n",
      "0.6129032258064516\n",
      "Precisión del modelo F:\n",
      "0.7338129496402878\n"
     ]
    }
   ],
   "source": [
    "#Calculo la precisión del modelo\n",
    "from sklearn.metrics import precision_score\n",
    "\n",
    "precision = precision_score(y_test, y_pred, average=\"binary\", pos_label=1)\n",
    "print('Precisión del modelo T:')\n",
    "print(precision)\n",
    "\n",
    "#Calculo la precisión del modelo Yes=1 No=0\n",
    "from sklearn.metrics import precision_score\n",
    "\n",
    "precision = precision_score(y_test, y_pred, average=\"binary\", pos_label=0)\n",
    "print('Precisión del modelo F:')\n",
    "print(precision)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Exactitud del modelo:\n",
      "0.6814210832847991\n"
     ]
    }
   ],
   "source": [
    "#Calculo la exactitud del modelo\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "exactitud = accuracy_score(y_test, y_pred)\n",
    "print('Exactitud del modelo:')\n",
    "print(exactitud)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sensibilidad del modelo T:\n",
      "0.6377622377622377\n",
      "Sensibilidad del modelo F:\n",
      "0.7125748502994012\n"
     ]
    }
   ],
   "source": [
    "#Calculo la sensibilidad del modelo\n",
    "from sklearn.metrics import recall_score\n",
    "\n",
    "sensibilidad = recall_score(y_test, y_pred, average=\"binary\", pos_label=1)\n",
    "print('Sensibilidad del modelo T:')\n",
    "print(sensibilidad)\n",
    "\n",
    "#Calculo la sensibilidad del modelo yes=1 No=0\n",
    "from sklearn.metrics import recall_score\n",
    "\n",
    "sensibilidad = recall_score(y_test, y_pred, average=\"binary\", pos_label=0)\n",
    "print('Sensibilidad del modelo F:')\n",
    "print(sensibilidad)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Puntaje F1 del modelo:\n",
      "0.6250856751199452\n"
     ]
    }
   ],
   "source": [
    "# el puntaje F1 que es una combinación entre la precisión y la sensibilidad, para esto importamos f1_score.\n",
    "#Calculo el Puntaje F1 del modelo\n",
    "from sklearn.metrics import f1_score\n",
    "\n",
    "puntajef1 = f1_score(y_test, y_pred, average=\"binary\", pos_label=1)\n",
    "print('Puntaje F1 del modelo:')\n",
    "print(puntajef1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "room_type"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Convertir room_type en variable dicotómica\n",
    "Vamos a convertir room_type en dos categorías:\n",
    "- \"Entire home/apt\" = 1\n",
    "- Otros tipos (Private room, Shared room) = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Valores únicos en room_type: ['Entire home/apt' 'Hotel room' 'Private room' 'Shared room']\n",
      "\n",
      "Valores únicos en room_type_binary: [0 1]\n",
      "\n",
      "Distribución de room_type_binary:\n",
      "room_type_binary\n",
      "1    4992\n",
      "0     731\n",
      "Name: count, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "# Primero veamos los valores únicos actuales\n",
    "print(\"Valores únicos en room_type:\", np.unique(df['room_type']))\n",
    "\n",
    "# Convertimos room_type a variable dicotómica\n",
    "df['room_type_binary'] = (df['room_type'] == 'Entire home/apt').astype(int)\n",
    "\n",
    "# Verificamos la conversión\n",
    "print(\"\\nValores únicos en room_type_binary:\", np.unique(df['room_type_binary']))\n",
    "print(\"\\nDistribución de room_type_binary:\")\n",
    "print(df['room_type_binary'].value_counts())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Declaramos las variables dependientes e independientes para la regresión Logística\n",
    "Vars_Indep = df[['price', 'accommodates', 'bathrooms', 'bedrooms']]\n",
    "Var_Dep = df['room_type_binary']\n",
    "\n",
    "#Redefinimos las variables \n",
    "X = Vars_Indep\n",
    "y = Var_Dep\n",
    "\n",
    "#Dividimos el conjunto de datos en la parte de entrenamiento y prueba:\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Se escalan todos los datos\n",
    "escalar = StandardScaler()\n",
    "\n",
    "#Para realizar el escalamiento de las variables “X” tanto de entrenamiento como de prueba, utilizaremos fit_transform\n",
    "X_train = escalar.fit_transform(X_train)\n",
    "X_test = escalar.transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Valores únicos en y_test: [0 1]\n",
      "Valores únicos en y_pred: [0 1]\n"
     ]
    }
   ],
   "source": [
    "#Definimos el algoritmo a utilizar\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "algoritmo = LogisticRegression()\n",
    "\n",
    "#Entrenamos el modelo\n",
    "algoritmo.fit(X_train, y_train)\n",
    "\n",
    "#Realizamos una predicción\n",
    "y_pred = algoritmo.predict(X_test) \n",
    "y_pred\n",
    "\n",
    "# Verificar los valores únicos en y_test y y_pred\n",
    "print(\"Valores únicos en y_test:\", np.unique(y_test))\n",
    "print(\"Valores únicos en y_pred:\", np.unique(y_pred))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Matriz de Confusión:\n",
      "[[  69  142]\n",
      " [   5 1501]]\n"
     ]
    }
   ],
   "source": [
    "#Verifico la matriz de Confusión\n",
    "from sklearn.metrics import confusion_matrix\n",
    "matriz = confusion_matrix(y_test, y_pred)\n",
    "print('Matriz de Confusión:')\n",
    "print(matriz)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Precisión del modelo T:\n",
      "0.913572732805843\n",
      "Precisión del modelo F:\n",
      "0.9324324324324325\n"
     ]
    }
   ],
   "source": [
    "#Calculo la precisión del modelo\n",
    "from sklearn.metrics import precision_score\n",
    "\n",
    "precision = precision_score(y_test, y_pred, average=\"binary\", pos_label=1)\n",
    "print('Precisión del modelo T:')\n",
    "print(precision)\n",
    "\n",
    "#Calculo la precisión del modelo Yes=1 No=0\n",
    "from sklearn.metrics import precision_score\n",
    "\n",
    "precision = precision_score(y_test, y_pred, average=\"binary\", pos_label=0)\n",
    "print('Precisión del modelo F:')\n",
    "print(precision)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Exactitud del modelo:\n",
      "0.9143855562026791\n"
     ]
    }
   ],
   "source": [
    "#Calculo la exactitud del modelo\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "exactitud = accuracy_score(y_test, y_pred)\n",
    "print('Exactitud del modelo:')\n",
    "print(exactitud)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sensibilidad del modelo T:\n",
      "0.9966799468791501\n",
      "Sensibilidad del modelo F:\n",
      "0.32701421800947866\n"
     ]
    }
   ],
   "source": [
    "#Calculo la sensibilidad del modelo\n",
    "from sklearn.metrics import recall_score\n",
    "\n",
    "sensibilidad = recall_score(y_test, y_pred, average=\"binary\", pos_label=1)\n",
    "print('Sensibilidad del modelo T:')\n",
    "print(sensibilidad)\n",
    "\n",
    "#Calculo la sensibilidad del modelo yes=1 No=0\n",
    "from sklearn.metrics import recall_score\n",
    "\n",
    "sensibilidad = recall_score(y_test, y_pred, average=\"binary\", pos_label=0)\n",
    "print('Sensibilidad del modelo F:')\n",
    "print(sensibilidad)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Puntaje F1 del modelo:\n",
      "0.9533185138139092\n"
     ]
    }
   ],
   "source": [
    "# el puntaje F1 que es una combinación entre la precisión y la sensibilidad, para esto importamos f1_score.\n",
    "#Calculo el Puntaje F1 del modelo\n",
    "from sklearn.metrics import f1_score\n",
    "\n",
    "puntajef1 = f1_score(y_test, y_pred, average=\"binary\", pos_label=1)\n",
    "print('Puntaje F1 del modelo:')\n",
    "print(puntajef1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "host_response_time"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Convertir host_response_time en variable dicotómica\n",
    "Vamos a convertir host_response_time en dos categorías:\n",
    "- Respuesta rápida (within an hour) = 1\n",
    "- Respuesta más lenta (más de una hora) = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Valores únicos en host_response_time: ['a few days or more' 'within a day' 'within a few hours' 'within an hour']\n",
      "\n",
      "Valores únicos en response_time_binary: [0 1]\n",
      "\n",
      "Distribución de response_time_binary:\n",
      "response_time_binary\n",
      "1    4651\n",
      "0    1072\n",
      "Name: count, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "# Primero veamos los valores únicos actuales\n",
    "print(\"Valores únicos en host_response_time:\", np.unique(df['host_response_time']))\n",
    "\n",
    "# Convertimos host_response_time a variable dicotómica\n",
    "df['response_time_binary'] = (df['host_response_time'] == 'within an hour').astype(int)\n",
    "\n",
    "# Verificamos la conversión\n",
    "print(\"\\nValores únicos en response_time_binary:\", np.unique(df['response_time_binary']))\n",
    "print(\"\\nDistribución de response_time_binary:\")\n",
    "print(df['response_time_binary'].value_counts())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Distribución de clases antes del balanceo:\n",
      "response_time_binary\n",
      "1    3256\n",
      "0     750\n",
      "Name: count, dtype: int64\n",
      "\n",
      "Distribución de clases después del balanceo:\n",
      "response_time_binary\n",
      "1    3256\n",
      "0    3256\n",
      "Name: count, dtype: int64\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\gaboo\\AppData\\Local\\Temp\\ipykernel_15348\\2310242258.py:14: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  Vars_Indep['host_acceptance_rate'] = Vars_Indep['host_acceptance_rate'].fillna('0%')\n",
      "C:\\Users\\gaboo\\AppData\\Local\\Temp\\ipykernel_15348\\2310242258.py:16: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  Vars_Indep['host_acceptance_rate'] = Vars_Indep['host_acceptance_rate'].apply(lambda x: float(str(x).rstrip('%')) / 100)\n"
     ]
    }
   ],
   "source": [
    "# Mostrar la distribución original de las clases antes del balanceo\n",
    "print(\"Distribución de clases antes del balanceo:\")\n",
    "print(pd.Series(y_train).value_counts())\n",
    "\n",
    "# Importamos SMOTE para el balanceo de datos\n",
    "from imblearn.over_sampling import SMOTE\n",
    "\n",
    "#Declaramos las variables dependientes e independientes para la regresión Logística\n",
    "Vars_Indep = df[['host_acceptance_rate', 'host_is_superhost', 'review_scores_communication']]\n",
    "Var_Dep = df['response_time_binary']\n",
    "\n",
    "# Convertir host_acceptance_rate a numérico\n",
    "# Primero reemplazamos los valores nulos con '0%'\n",
    "Vars_Indep['host_acceptance_rate'] = Vars_Indep['host_acceptance_rate'].fillna('0%')\n",
    "# Ahora convertimos a float\n",
    "Vars_Indep['host_acceptance_rate'] = Vars_Indep['host_acceptance_rate'].apply(lambda x: float(str(x).rstrip('%')) / 100)\n",
    "\n",
    "#Redefinimos las variables \n",
    "X = Vars_Indep\n",
    "y = Var_Dep\n",
    "\n",
    "#Dividimos el conjunto de datos en la parte de entrenamiento y prueba:\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=42)\n",
    "\n",
    "# Aplicamos SMOTE solo a los datos de entrenamiento\n",
    "smote = SMOTE(random_state=42)\n",
    "X_train_balanced, y_train_balanced = smote.fit_resample(X_train, y_train)\n",
    "\n",
    "# Verificamos la distribución después del balanceo\n",
    "print(\"\\nDistribución de clases después del balanceo:\")\n",
    "print(pd.Series(y_train_balanced).value_counts())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Se escalan todos los datos\n",
    "escalar = StandardScaler()\n",
    "\n",
    "#Para realizar el escalamiento de las variables \"X\" tanto de entrenamiento como de prueba, utilizaremos fit_transform\n",
    "X_train_balanced = escalar.fit_transform(X_train_balanced)\n",
    "X_test = escalar.transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Valores únicos en y_test: [0 1]\n",
      "Valores únicos en y_pred: [0 1]\n",
      "\n",
      "Distribución de las predicciones:\n",
      "0    1002\n",
      "1     715\n",
      "Name: count, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "#Definimos el algoritmo a utilizar\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "algoritmo = LogisticRegression()\n",
    "\n",
    "#Entrenamos el modelo con los datos balanceados\n",
    "algoritmo.fit(X_train_balanced, y_train_balanced)\n",
    "\n",
    "#Realizamos una predicción\n",
    "y_pred = algoritmo.predict(X_test) \n",
    "y_pred\n",
    "\n",
    "# Verificar los valores únicos en y_test y y_pred\n",
    "print(\"Valores únicos en y_test:\", np.unique(y_test))\n",
    "print(\"Valores únicos en y_pred:\", np.unique(y_pred))\n",
    "\n",
    "# Mostrar la distribución de las predicciones\n",
    "print(\"\\nDistribución de las predicciones:\")\n",
    "print(pd.Series(y_pred).value_counts())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Matriz de Confusión:\n",
      "[[269  53]\n",
      " [733 662]]\n"
     ]
    }
   ],
   "source": [
    "#Verifico la matriz de Confusión\n",
    "from sklearn.metrics import confusion_matrix\n",
    "matriz = confusion_matrix(y_test, y_pred)\n",
    "print('Matriz de Confusión:')\n",
    "print(matriz)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Precisión del modelo T:\n",
      "0.9258741258741259\n",
      "Precisión del modelo F:\n",
      "0.2684630738522954\n"
     ]
    }
   ],
   "source": [
    "#Calculo la precisión del modelo\n",
    "from sklearn.metrics import precision_score\n",
    "\n",
    "precision = precision_score(y_test, y_pred, average=\"binary\", pos_label=1)\n",
    "print('Precisión del modelo T:')\n",
    "print(precision)\n",
    "\n",
    "#Calculo la precisión del modelo Yes=1 No=0\n",
    "from sklearn.metrics import precision_score\n",
    "\n",
    "precision = precision_score(y_test, y_pred, average=\"binary\", pos_label=0)\n",
    "print('Precisión del modelo F:')\n",
    "print(precision)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Exactitud del modelo:\n",
      "0.5422248107163657\n"
     ]
    }
   ],
   "source": [
    "#Calculo la exactitud del modelo\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "exactitud = accuracy_score(y_test, y_pred)\n",
    "print('Exactitud del modelo:')\n",
    "print(exactitud)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sensibilidad del modelo T:\n",
      "0.4745519713261649\n",
      "Sensibilidad del modelo F:\n",
      "0.8354037267080745\n"
     ]
    }
   ],
   "source": [
    "#Calculo la sensibilidad del modelo\n",
    "from sklearn.metrics import recall_score\n",
    "\n",
    "sensibilidad = recall_score(y_test, y_pred, average=\"binary\", pos_label=1)\n",
    "print('Sensibilidad del modelo T:')\n",
    "print(sensibilidad)\n",
    "\n",
    "#Calculo la sensibilidad del modelo yes=1 No=0\n",
    "from sklearn.metrics import recall_score\n",
    "\n",
    "sensibilidad = recall_score(y_test, y_pred, average=\"binary\", pos_label=0)\n",
    "print('Sensibilidad del modelo F:')\n",
    "print(sensibilidad)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Puntaje F1 del modelo:\n",
      "0.6274881516587678\n"
     ]
    }
   ],
   "source": [
    "# el puntaje F1 que es una combinación entre la precisión y la sensibilidad, para esto importamos f1_score.\n",
    "#Calculo el Puntaje F1 del modelo\n",
    "from sklearn.metrics import f1_score\n",
    "\n",
    "puntajef1 = f1_score(y_test, y_pred, average=\"binary\", pos_label=1)\n",
    "print('Puntaje F1 del modelo:')\n",
    "print(puntajef1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Convertir availability_365 en variable dicotómica\n",
    "Vamos a convertir availability_365 en dos categorías:\n",
    "- Alta disponibilidad (>180 días) = 1\n",
    "- Baja disponibilidad (≤180 días) = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Estadísticas de availability_365:\n",
      "count    5723.000000\n",
      "mean      253.241482\n",
      "std       118.140893\n",
      "min         0.000000\n",
      "25%       170.000000\n",
      "50%       299.000000\n",
      "75%       355.000000\n",
      "max       365.000000\n",
      "Name: availability_365, dtype: float64\n",
      "\n",
      "Valores únicos en availability_binary: [0 1]\n",
      "\n",
      "Distribución de availability_binary:\n",
      "availability_binary\n",
      "1    4138\n",
      "0    1585\n",
      "Name: count, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "# Primero veamos los valores únicos actuales y la distribución\n",
    "print(\"Estadísticas de availability_365:\")\n",
    "print(df['availability_365'].describe())\n",
    "\n",
    "# Convertimos availability_365 a variable dicotómica\n",
    "df['availability_binary'] = (df['availability_365'] > 180).astype(int)\n",
    "\n",
    "# Verificamos la conversión\n",
    "print(\"\\nValores únicos en availability_binary:\", np.unique(df['availability_binary']))\n",
    "print(\"\\nDistribución de availability_binary:\")\n",
    "print(df['availability_binary'].value_counts())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Distribución de clases antes del balanceo:\n",
      "availability_binary\n",
      "1    2896\n",
      "0    1110\n",
      "Name: count, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "# Preparamos los datos para el modelo de regresión logística\n",
    "Vars_Indep = df[['price', 'minimum_nights', 'review_scores_rating', 'reviews_per_month']]\n",
    "Var_Dep = df['availability_binary']\n",
    "\n",
    "# Redefinimos las variables\n",
    "X = Vars_Indep\n",
    "y = Var_Dep\n",
    "\n",
    "# Dividimos el conjunto de datos\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=42)\n",
    "\n",
    "# Mostramos la distribución original\n",
    "print(\"Distribución de clases antes del balanceo:\")\n",
    "print(pd.Series(y_train).value_counts())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Distribución de clases después del balanceo:\n",
      "availability_binary\n",
      "1    2896\n",
      "0    2896\n",
      "Name: count, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "# Aplicamos SMOTE para balancear las clases\n",
    "smote = SMOTE(random_state=42)\n",
    "X_train_balanced, y_train_balanced = smote.fit_resample(X_train, y_train)\n",
    "\n",
    "# Verificamos la distribución después del balanceo\n",
    "print(\"\\nDistribución de clases después del balanceo:\")\n",
    "print(pd.Series(y_train_balanced).value_counts())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Distribución de las predicciones:\n",
      "1    894\n",
      "0    823\n",
      "Name: count, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "# Escalamos los datos\n",
    "escalar = StandardScaler()\n",
    "X_train_balanced = escalar.fit_transform(X_train_balanced)\n",
    "X_test = escalar.transform(X_test)\n",
    "\n",
    "# Entrenamos el modelo\n",
    "algoritmo = LogisticRegression()\n",
    "algoritmo.fit(X_train_balanced, y_train_balanced)\n",
    "\n",
    "# Realizamos predicciones\n",
    "y_pred = algoritmo.predict(X_test)\n",
    "\n",
    "# Mostramos la distribución de las predicciones\n",
    "print(\"Distribución de las predicciones:\")\n",
    "print(pd.Series(y_pred).value_counts())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Matriz de Confusión:\n",
      "[[266 209]\n",
      " [557 685]]\n",
      "\n",
      "Precisión para alta disponibilidad (1): 0.7662192393736018\n",
      "Precisión para baja disponibilidad (0): 0.32320777642770354\n",
      "\n",
      "Sensibilidad para alta disponibilidad (1): 0.5515297906602254\n",
      "Sensibilidad para baja disponibilidad (0): 0.56\n",
      "\n",
      "Exactitud del modelo: 0.5538730343622598\n",
      "\n",
      "Puntaje F1: 0.6413857677902621\n"
     ]
    }
   ],
   "source": [
    "# Evaluación del modelo\n",
    "# Matriz de confusión\n",
    "matriz = confusion_matrix(y_test, y_pred)\n",
    "print('Matriz de Confusión:')\n",
    "print(matriz)\n",
    "\n",
    "# Precisión\n",
    "precision_pos = precision_score(y_test, y_pred, pos_label=1)\n",
    "precision_neg = precision_score(y_test, y_pred, pos_label=0)\n",
    "print('\\nPrecisión para alta disponibilidad (1):', precision_pos)\n",
    "print('Precisión para baja disponibilidad (0):', precision_neg)\n",
    "\n",
    "# Sensibilidad (Recall)\n",
    "recall_pos = recall_score(y_test, y_pred, pos_label=1)\n",
    "recall_neg = recall_score(y_test, y_pred, pos_label=0)\n",
    "print('\\nSensibilidad para alta disponibilidad (1):', recall_pos)\n",
    "print('Sensibilidad para baja disponibilidad (0):', recall_neg)\n",
    "\n",
    "# Exactitud\n",
    "exactitud = accuracy_score(y_test, y_pred)\n",
    "print('\\nExactitud del modelo:', exactitud)\n",
    "\n",
    "# F1 Score\n",
    "f1 = f1_score(y_test, y_pred, pos_label=1)\n",
    "print('\\nPuntaje F1:', f1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Convertir property_type en variable dicotómica\n",
    "Vamos a convertir property_type en dos categorías:\n",
    "- \"Apartment/Condo\" (Apartamentos y Condominios) = 1\n",
    "- Otros tipos de propiedades = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Valores únicos en property_type:\n",
      "property_type\n",
      "Entire rental unit                    2273\n",
      "Entire home                           1655\n",
      "Private room in home                   453\n",
      "Entire condo                           359\n",
      "Entire townhouse                       235\n",
      "Entire guesthouse                      162\n",
      "Room in hotel                          160\n",
      "Private room in rental unit             59\n",
      "Entire loft                             56\n",
      "Entire serviced apartment               46\n",
      "Entire guest suite                      38\n",
      "Private room in townhouse               35\n",
      "Shared room in home                     27\n",
      "Entire bungalow                         23\n",
      "Tiny home                               23\n",
      "Private room in condo                   21\n",
      "Room in boutique hotel                  19\n",
      "Entire villa                            15\n",
      "Private room in serviced apartment      10\n",
      "Camper/RV                                9\n",
      "Entire cottage                           8\n",
      "Shipping container                       5\n",
      "Private room in bungalow                 5\n",
      "Private room in guesthouse               5\n",
      "Private room                             3\n",
      "Boat                                     2\n",
      "Private room in cottage                  2\n",
      "Tent                                     2\n",
      "Entire vacation home                     2\n",
      "Private room in guest suite              2\n",
      "Entire place                             2\n",
      "Farm stay                                1\n",
      "Private room in loft                     1\n",
      "Shared room in serviced apartment        1\n",
      "Treehouse                                1\n",
      "Earthen home                             1\n",
      "Barn                                     1\n",
      "Private room in tent                     1\n",
      "Name: count, dtype: int64\n",
      "\n",
      "Valores únicos en property_type_binary: [0 1]\n",
      "\n",
      "Distribución de property_type_binary:\n",
      "property_type_binary\n",
      "0    5229\n",
      "1     494\n",
      "Name: count, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "# Primero veamos los valores únicos actuales\n",
    "print(\"Valores únicos en property_type:\")\n",
    "print(df['property_type'].value_counts())\n",
    "\n",
    "# Convertimos property_type a variable dicotómica\n",
    "df['property_type_binary'] = df['property_type'].str.contains('Apartment|Condo|Condominium|Loft', case=False).astype(int)\n",
    "\n",
    "# Verificamos la conversión\n",
    "print(\"\\nValores únicos en property_type_binary:\", np.unique(df['property_type_binary']))\n",
    "print(\"\\nDistribución de property_type_binary:\")\n",
    "print(df['property_type_binary'].value_counts(dropna=False))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Distribución de clases antes del balanceo:\n",
      "property_type_binary\n",
      "0    3686\n",
      "1     320\n",
      "Name: count, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "# Preparamos los datos para el modelo de regresión logística\n",
    "Vars_Indep = df[['price', 'bedrooms', 'bathrooms', 'review_scores_rating', 'review_scores_location']]\n",
    "Var_Dep = df['property_type_binary']\n",
    "\n",
    "# Manejamos los valores nulos en las variables independientes\n",
    "Vars_Indep = Vars_Indep.fillna(Vars_Indep.mean())\n",
    "\n",
    "# Redefinimos las variables\n",
    "X = Vars_Indep\n",
    "y = Var_Dep\n",
    "\n",
    "# Eliminamos las filas donde y es nulo\n",
    "mask = ~y.isnull()\n",
    "X = X[mask]\n",
    "y = y[mask]\n",
    "\n",
    "# Dividimos el conjunto de datos\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=42)\n",
    "\n",
    "# Mostramos la distribución original\n",
    "print(\"Distribución de clases antes del balanceo:\")\n",
    "print(pd.Series(y_train).value_counts())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Valores únicos en property_type_binary en todos los datos:\n",
      "[1 0]\n",
      "\n",
      "Distribución en todos los datos:\n",
      "property_type_binary\n",
      "0    5229\n",
      "1     494\n",
      "Name: count, dtype: int64\n",
      "\n",
      "Cantidad de valores nulos:\n",
      "0\n",
      "\n",
      "Verificamos los datos en las variables independientes:\n",
      "Valores nulos en X:\n",
      "price                     0\n",
      "bedrooms                  0\n",
      "bathrooms                 0\n",
      "review_scores_rating      0\n",
      "review_scores_location    0\n",
      "dtype: int64\n"
     ]
    }
   ],
   "source": [
    "# Verificamos los valores únicos y la distribución en los datos originales\n",
    "print(\"Valores únicos en property_type_binary en todos los datos:\")\n",
    "print(df['property_type_binary'].unique())\n",
    "print(\"\\nDistribución en todos los datos:\")\n",
    "print(df['property_type_binary'].value_counts(dropna=False))\n",
    "\n",
    "# Verificamos si hay valores nulos\n",
    "print(\"\\nCantidad de valores nulos:\")\n",
    "print(df['property_type_binary'].isnull().sum())\n",
    "\n",
    "# Verificamos los valores en X\n",
    "print(\"\\nVerificamos los datos en las variables independientes:\")\n",
    "print(\"Valores nulos en X:\")\n",
    "print(Vars_Indep.isnull().sum())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Número de clases únicas en y_train: 2\n",
      "Valores únicos: [0 1]\n",
      "\n",
      "Distribución de clases después del balanceo:\n",
      "property_type_binary\n",
      "0    3686\n",
      "1    3686\n",
      "Name: count, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "# Verificamos que tenemos al menos dos clases antes de aplicar SMOTE\n",
    "unique_classes = len(np.unique(y_train))\n",
    "print(f\"Número de clases únicas en y_train: {unique_classes}\")\n",
    "print(\"Valores únicos:\", np.unique(y_train))\n",
    "\n",
    "if unique_classes > 1:\n",
    "    # Aplicamos SMOTE para balancear las clases\n",
    "    smote = SMOTE(random_state=42)\n",
    "    X_train_balanced, y_train_balanced = smote.fit_resample(X_train, y_train)\n",
    "    \n",
    "    # Verificamos la distribución después del balanceo\n",
    "    print(\"\\nDistribución de clases después del balanceo:\")\n",
    "    print(pd.Series(y_train_balanced).value_counts())\n",
    "else:\n",
    "    print(\"\\n¡ADVERTENCIA! Solo hay una clase en los datos de entrenamiento.\")\n",
    "    print(\"No se puede aplicar SMOTE. Usando los datos sin balancear.\")\n",
    "    X_train_balanced, y_train_balanced = X_train, y_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Distribución de las predicciones:\n",
      "1    891\n",
      "0    826\n",
      "Name: count, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "# Escalamos los datos\n",
    "escalar = StandardScaler()\n",
    "X_train_balanced = escalar.fit_transform(X_train_balanced)\n",
    "X_test = escalar.transform(X_test)\n",
    "\n",
    "# Entrenamos el modelo\n",
    "algoritmo = LogisticRegression()\n",
    "algoritmo.fit(X_train_balanced, y_train_balanced)\n",
    "\n",
    "# Realizamos predicciones\n",
    "y_pred = algoritmo.predict(X_test)\n",
    "\n",
    "# Mostramos la distribución de las predicciones\n",
    "print(\"Distribución de las predicciones:\")\n",
    "print(pd.Series(y_pred).value_counts())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Matriz de Confusión:\n",
      "[[774 769]\n",
      " [ 52 122]]\n",
      "\n",
      "Precisión para Apartment/Condo (1): 0.13692480359147025\n",
      "Precisión para otros tipos (0): 0.937046004842615\n",
      "\n",
      "Sensibilidad para Apartment/Condo (1): 0.7011494252873564\n",
      "Sensibilidad para otros tipos (0): 0.5016202203499676\n",
      "\n",
      "Exactitud del modelo: 0.5218404193360513\n",
      "\n",
      "Puntaje F1: 0.2291079812206573\n"
     ]
    }
   ],
   "source": [
    "# Evaluación del modelo\n",
    "# Matriz de confusión\n",
    "matriz = confusion_matrix(y_test, y_pred)\n",
    "print('Matriz de Confusión:')\n",
    "print(matriz)\n",
    "\n",
    "# Precisión\n",
    "precision_pos = precision_score(y_test, y_pred, pos_label=1)\n",
    "precision_neg = precision_score(y_test, y_pred, pos_label=0)\n",
    "print('\\nPrecisión para Apartment/Condo (1):', precision_pos)\n",
    "print('Precisión para otros tipos (0):', precision_neg)\n",
    "\n",
    "# Sensibilidad (Recall)\n",
    "recall_pos = recall_score(y_test, y_pred, pos_label=1)\n",
    "recall_neg = recall_score(y_test, y_pred, pos_label=0)\n",
    "print('\\nSensibilidad para Apartment/Condo (1):', recall_pos)\n",
    "print('Sensibilidad para otros tipos (0):', recall_neg)\n",
    "\n",
    "# Exactitud\n",
    "exactitud = accuracy_score(y_test, y_pred)\n",
    "print('\\nExactitud del modelo:', exactitud)\n",
    "\n",
    "# F1 Score\n",
    "f1 = f1_score(y_test, y_pred, pos_label=1)\n",
    "print('\\nPuntaje F1:', f1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Convertir host_response_rate en variable dicotómica\n",
    "Vamos a convertir host_response_rate en dos categorías:\n",
    "- Alta tasa de respuesta (≥90%) = 1\n",
    "- Baja tasa de respuesta (<90%) = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Distribución de host_response_rate original:\n",
      "host_response_rate\n",
      "0.95      86\n",
      "0.96     139\n",
      "0.97      62\n",
      "0.98     176\n",
      "0.99     273\n",
      "1.00    4987\n",
      "Name: count, dtype: int64\n",
      "\n",
      "Estadísticas de host_response_rate_clean:\n",
      "count    5723.000000\n",
      "mean        0.996860\n",
      "std         0.009665\n",
      "min         0.950000\n",
      "25%         1.000000\n",
      "50%         1.000000\n",
      "75%         1.000000\n",
      "max         1.000000\n",
      "Name: host_response_rate_clean, dtype: float64\n",
      "\n",
      "Valores únicos en response_rate_binary: [0 1]\n",
      "\n",
      "Distribución de response_rate_binary:\n",
      "response_rate_binary\n",
      "1    5436\n",
      "0     287\n",
      "Name: count, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "# Primero veamos los valores únicos actuales y su distribución\n",
    "print(\"Distribución de host_response_rate original:\")\n",
    "print(df['host_response_rate'].value_counts().sort_index())\n",
    "\n",
    "# Convertimos host_response_rate a numérico\n",
    "# Primero reemplazamos los valores nulos con '0%'\n",
    "df['host_response_rate_clean'] = df['host_response_rate'].fillna('0%')\n",
    "# Convertimos a float (asumiendo que los valores ya están en decimal)\n",
    "df['host_response_rate_clean'] = df['host_response_rate_clean'].apply(lambda x: float(str(x)))\n",
    "\n",
    "# Analizamos la distribución de los valores numéricos\n",
    "print(\"\\nEstadísticas de host_response_rate_clean:\")\n",
    "print(df['host_response_rate_clean'].describe())\n",
    "\n",
    "# Convertimos a binario (1 para ≥98%, 0 para <98%)\n",
    "df['response_rate_binary'] = (df['host_response_rate_clean'] >= 0.98).astype(int)\n",
    "\n",
    "# Verificamos la conversión\n",
    "print(\"\\nValores únicos en response_rate_binary:\", np.unique(df['response_rate_binary']))\n",
    "print(\"\\nDistribución de response_rate_binary:\")\n",
    "print(df['response_rate_binary'].value_counts())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Distribución de clases antes del balanceo:\n",
      "response_rate_binary\n",
      "1    3782\n",
      "0     224\n",
      "Name: count, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "# Preparamos los datos para el modelo de regresión logística\n",
    "Vars_Indep = df[['review_scores_communication', 'review_scores_accuracy', 'number_of_reviews', 'host_is_superhost']]\n",
    "Var_Dep = df['response_rate_binary']\n",
    "\n",
    "# Redefinimos las variables\n",
    "X = Vars_Indep\n",
    "y = Var_Dep\n",
    "\n",
    "# Dividimos el conjunto de datos\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=42)\n",
    "\n",
    "# Mostramos la distribución original\n",
    "print(\"Distribución de clases antes del balanceo:\")\n",
    "print(pd.Series(y_train).value_counts())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Distribución original de response_rate_binary:\n",
      "response_rate_binary\n",
      "1    5436\n",
      "0     287\n",
      "Name: count, dtype: int64\n",
      "\n",
      "Cantidad de valores nulos:\n",
      "0\n"
     ]
    }
   ],
   "source": [
    "# Verificamos la distribución de los datos originales y los valores nulos\n",
    "print(\"Distribución original de response_rate_binary:\")\n",
    "print(df['response_rate_binary'].value_counts(dropna=False))\n",
    "print(\"\\nCantidad de valores nulos:\")\n",
    "print(df['response_rate_binary'].isnull().sum())\n",
    "\n",
    "# Si hay valores nulos, los eliminamos\n",
    "if df['response_rate_binary'].isnull().any():\n",
    "    mask = ~df['response_rate_binary'].isnull()\n",
    "    Vars_Indep = Vars_Indep[mask]\n",
    "    Var_Dep = df['response_rate_binary'][mask]\n",
    "    print(\"\\nDistribución después de eliminar nulos:\")\n",
    "    print(Var_Dep.value_counts())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Número de clases únicas en y_train: 2\n",
      "Valores únicos: [0 1]\n",
      "\n",
      "Distribución de clases después del balanceo:\n",
      "response_rate_binary\n",
      "1    3782\n",
      "0    3782\n",
      "Name: count, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "# Verificamos que tenemos al menos dos clases antes de aplicar SMOTE\n",
    "unique_classes = len(np.unique(y_train))\n",
    "print(f\"Número de clases únicas en y_train: {unique_classes}\")\n",
    "print(\"Valores únicos:\", np.unique(y_train))\n",
    "\n",
    "if unique_classes > 1:\n",
    "    # Aplicamos SMOTE para balancear las clases\n",
    "    smote = SMOTE(random_state=42)\n",
    "    X_train_balanced, y_train_balanced = smote.fit_resample(X_train, y_train)\n",
    "    \n",
    "    # Verificamos la distribución después del balanceo\n",
    "    print(\"\\nDistribución de clases después del balanceo:\")\n",
    "    print(pd.Series(y_train_balanced).value_counts())\n",
    "else:\n",
    "    print(\"\\n¡ADVERTENCIA! Solo hay una clase en los datos de entrenamiento.\")\n",
    "    print(\"No se puede aplicar SMOTE. Usando los datos sin balancear.\")\n",
    "    X_train_balanced, y_train_balanced = X_train, y_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Distribución de las predicciones:\n",
      "1    899\n",
      "0    818\n",
      "Name: count, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "# Escalamos los datos\n",
    "escalar = StandardScaler()\n",
    "X_train_balanced = escalar.fit_transform(X_train_balanced)\n",
    "X_test = escalar.transform(X_test)\n",
    "\n",
    "# Entrenamos el modelo\n",
    "algoritmo = LogisticRegression()\n",
    "algoritmo.fit(X_train_balanced, y_train_balanced)\n",
    "\n",
    "# Realizamos predicciones\n",
    "y_pred = algoritmo.predict(X_test)\n",
    "\n",
    "# Mostramos la distribución de las predicciones\n",
    "print(\"Distribución de las predicciones:\")\n",
    "print(pd.Series(y_pred).value_counts())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Matriz de Confusión:\n",
      "[[ 56   7]\n",
      " [762 892]]\n",
      "\n",
      "Precisión para alta tasa de respuesta (1): 0.9922135706340378\n",
      "Precisión para baja tasa de respuesta (0): 0.06845965770171149\n",
      "\n",
      "Sensibilidad para alta tasa de respuesta (1): 0.5392986698911729\n",
      "Sensibilidad para baja tasa de respuesta (0): 0.8888888888888888\n",
      "\n",
      "Exactitud del modelo: 0.5521258008153757\n",
      "\n",
      "Puntaje F1: 0.6987857422640031\n"
     ]
    }
   ],
   "source": [
    "# Evaluación del modelo\n",
    "# Matriz de confusión\n",
    "matriz = confusion_matrix(y_test, y_pred)\n",
    "print('Matriz de Confusión:')\n",
    "print(matriz)\n",
    "\n",
    "# Precisión\n",
    "precision_pos = precision_score(y_test, y_pred, pos_label=1)\n",
    "precision_neg = precision_score(y_test, y_pred, pos_label=0)\n",
    "print('\\nPrecisión para alta tasa de respuesta (1):', precision_pos)\n",
    "print('Precisión para baja tasa de respuesta (0):', precision_neg)\n",
    "\n",
    "# Sensibilidad (Recall)\n",
    "recall_pos = recall_score(y_test, y_pred, pos_label=1)\n",
    "recall_neg = recall_score(y_test, y_pred, pos_label=0)\n",
    "print('\\nSensibilidad para alta tasa de respuesta (1):', recall_pos)\n",
    "print('Sensibilidad para baja tasa de respuesta (0):', recall_neg)\n",
    "\n",
    "# Exactitud\n",
    "exactitud = accuracy_score(y_test, y_pred)\n",
    "print('\\nExactitud del modelo:', exactitud)\n",
    "\n",
    "# F1 Score\n",
    "f1 = f1_score(y_test, y_pred, pos_label=1)\n",
    "print('\\nPuntaje F1:', f1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Convertir host_acceptance_rate en variable dicotómica\n",
    "Vamos a convertir host_acceptance_rate en dos categorías:\n",
    "- Alta tasa de aceptación (≥85%) = 1\n",
    "- Baja tasa de aceptación (<85%) = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Distribución de host_acceptance_rate original:\n",
      "host_acceptance_rate\n",
      "0.70      16\n",
      "0.71       6\n",
      "0.72       3\n",
      "0.73      18\n",
      "0.74      23\n",
      "0.75      50\n",
      "0.76       9\n",
      "0.77      15\n",
      "0.78      42\n",
      "0.79      32\n",
      "0.80      56\n",
      "0.81      31\n",
      "0.82      45\n",
      "0.83      47\n",
      "0.84      15\n",
      "0.85      18\n",
      "0.86     104\n",
      "0.87      31\n",
      "0.88     100\n",
      "0.89      54\n",
      "0.90      44\n",
      "0.91      72\n",
      "0.92      58\n",
      "0.93      63\n",
      "0.94     118\n",
      "0.95     252\n",
      "0.96     230\n",
      "0.97     150\n",
      "0.98     309\n",
      "0.99     876\n",
      "1.00    2836\n",
      "Name: count, dtype: int64\n",
      "\n",
      "Estadísticas de host_acceptance_rate_clean:\n",
      "count    5723.000000\n",
      "mean        0.009659\n",
      "std         0.000611\n",
      "min         0.007000\n",
      "25%         0.009600\n",
      "50%         0.009900\n",
      "75%         0.010000\n",
      "max         0.010000\n",
      "Name: host_acceptance_rate_clean, dtype: float64\n",
      "\n",
      "Percentiles de host_acceptance_rate_clean:\n",
      "Percentil 25: 0.01\n",
      "Percentil 50: 0.01\n",
      "Percentil 75: 0.01\n",
      "\n",
      "Usando umbral de 0.01 (mediana)\n",
      "\n",
      "Valores únicos en acceptance_rate_binary: [0 1]\n",
      "\n",
      "Distribución de acceptance_rate_binary:\n",
      "acceptance_rate_binary\n",
      "1    3712\n",
      "0    2011\n",
      "Name: count, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "# Primero veamos los valores únicos actuales y su distribución\n",
    "print(\"Distribución de host_acceptance_rate original:\")\n",
    "print(df['host_acceptance_rate'].value_counts().sort_index())\n",
    "\n",
    "# Convertimos host_acceptance_rate a numérico\n",
    "# Primero reemplazamos los valores nulos con '0%'\n",
    "df['host_acceptance_rate_clean'] = df['host_acceptance_rate'].fillna('0%')\n",
    "# Convertimos a float\n",
    "df['host_acceptance_rate_clean'] = df['host_acceptance_rate_clean'].apply(lambda x: float(str(x).rstrip('%')) / 100)\n",
    "\n",
    "# Analizamos la distribución de los valores numéricos\n",
    "print(\"\\nEstadísticas de host_acceptance_rate_clean:\")\n",
    "print(df['host_acceptance_rate_clean'].describe())\n",
    "\n",
    "# Mostramos los percentiles para ayudar a elegir un mejor umbral\n",
    "print(\"\\nPercentiles de host_acceptance_rate_clean:\")\n",
    "percentiles = [25, 50, 75]\n",
    "for p in percentiles:\n",
    "    print(f\"Percentil {p}: {df['host_acceptance_rate_clean'].quantile(p/100):.2f}\")\n",
    "\n",
    "# Convertimos a binario usando el percentil 50 como umbral\n",
    "umbral = df['host_acceptance_rate_clean'].median()\n",
    "print(f\"\\nUsando umbral de {umbral:.2f} (mediana)\")\n",
    "df['acceptance_rate_binary'] = (df['host_acceptance_rate_clean'] >= umbral).astype(int)\n",
    "\n",
    "# Verificamos la conversión\n",
    "print(\"\\nValores únicos en acceptance_rate_binary:\", np.unique(df['acceptance_rate_binary']))\n",
    "print(\"\\nDistribución de acceptance_rate_binary:\")\n",
    "print(df['acceptance_rate_binary'].value_counts())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Distribución de clases antes del balanceo:\n",
      "acceptance_rate_binary\n",
      "1    2596\n",
      "0    1410\n",
      "Name: count, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "# Preparamos los datos para el modelo de regresión logística\n",
    "Vars_Indep = df[['review_scores_communication', 'host_response_rate', 'number_of_reviews', 'review_scores_rating']]\n",
    "Var_Dep = df['acceptance_rate_binary']\n",
    "\n",
    "# Manejamos los valores nulos en las variables independientes\n",
    "Vars_Indep = Vars_Indep.fillna(Vars_Indep.mean())\n",
    "\n",
    "# Redefinimos las variables\n",
    "X = Vars_Indep\n",
    "y = Var_Dep\n",
    "\n",
    "# Dividimos el conjunto de datos\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=42)\n",
    "\n",
    "# Mostramos la distribución original\n",
    "print(\"Distribución de clases antes del balanceo:\")\n",
    "print(pd.Series(y_train).value_counts())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Distribución de clases después del balanceo:\n",
      "acceptance_rate_binary\n",
      "0    2596\n",
      "1    2596\n",
      "Name: count, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "# Aplicamos SMOTE para balancear las clases\n",
    "smote = SMOTE(random_state=42)\n",
    "X_train_balanced, y_train_balanced = smote.fit_resample(X_train, y_train)\n",
    "\n",
    "# Verificamos la distribución después del balanceo\n",
    "print(\"\\nDistribución de clases después del balanceo:\")\n",
    "print(pd.Series(y_train_balanced).value_counts())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Distribución de las predicciones:\n",
      "1    1419\n",
      "0     298\n",
      "Name: count, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "# Escalamos los datos\n",
    "escalar = StandardScaler()\n",
    "X_train_balanced = escalar.fit_transform(X_train_balanced)\n",
    "X_test = escalar.transform(X_test)\n",
    "\n",
    "# Entrenamos el modelo\n",
    "algoritmo = LogisticRegression()\n",
    "algoritmo.fit(X_train_balanced, y_train_balanced)\n",
    "\n",
    "# Realizamos predicciones\n",
    "y_pred = algoritmo.predict(X_test)\n",
    "\n",
    "# Mostramos la distribución de las predicciones\n",
    "print(\"Distribución de las predicciones:\")\n",
    "print(pd.Series(y_pred).value_counts())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Matriz de Confusión:\n",
      "[[114 487]\n",
      " [184 932]]\n",
      "\n",
      "Precisión para alta tasa de aceptación (1): 0.656800563777308\n",
      "Precisión para baja tasa de aceptación (0): 0.3825503355704698\n",
      "\n",
      "Sensibilidad para alta tasa de aceptación (1): 0.8351254480286738\n",
      "Sensibilidad para baja tasa de aceptación (0): 0.1896838602329451\n",
      "\n",
      "Exactitud del modelo: 0.6092020966802563\n",
      "\n",
      "Puntaje F1: 0.7353057199211045\n"
     ]
    }
   ],
   "source": [
    "# Evaluación del modelo\n",
    "# Matriz de confusión\n",
    "matriz = confusion_matrix(y_test, y_pred)\n",
    "print('Matriz de Confusión:')\n",
    "print(matriz)\n",
    "\n",
    "# Precisión\n",
    "precision_pos = precision_score(y_test, y_pred, pos_label=1)\n",
    "precision_neg = precision_score(y_test, y_pred, pos_label=0)\n",
    "print('\\nPrecisión para alta tasa de aceptación (1):', precision_pos)\n",
    "print('Precisión para baja tasa de aceptación (0):', precision_neg)\n",
    "\n",
    "# Sensibilidad (Recall)\n",
    "recall_pos = recall_score(y_test, y_pred, pos_label=1)\n",
    "recall_neg = recall_score(y_test, y_pred, pos_label=0)\n",
    "print('\\nSensibilidad para alta tasa de aceptación (1):', recall_pos)\n",
    "print('Sensibilidad para baja tasa de aceptación (0):', recall_neg)\n",
    "\n",
    "# Exactitud\n",
    "exactitud = accuracy_score(y_test, y_pred)\n",
    "print('\\nExactitud del modelo:', exactitud)\n",
    "\n",
    "# F1 Score\n",
    "f1 = f1_score(y_test, y_pred, pos_label=1)\n",
    "print('\\nPuntaje F1:', f1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Convertir price en variable dicotómica\n",
    "Vamos a convertir price en dos categorías usando la mediana como punto de corte:\n",
    "- Precio alto (≥ mediana) = 1\n",
    "- Precio bajo (< mediana) = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Estadísticas de price:\n",
      "count    5723.000000\n",
      "mean      123.189411\n",
      "std        66.039277\n",
      "min        11.000000\n",
      "25%        80.000000\n",
      "50%       105.000000\n",
      "75%       147.000000\n",
      "max       382.000000\n",
      "Name: price, dtype: float64\n",
      "\n",
      "Percentiles de price:\n",
      "Percentil 25: $80.00\n",
      "Percentil 50: $105.00\n",
      "Percentil 75: $147.00\n",
      "\n",
      "Usando umbral de $105.00 (mediana)\n",
      "\n",
      "Valores únicos en price_binary: [0 1]\n",
      "\n",
      "Distribución de price_binary:\n",
      "price_binary\n",
      "1    3230\n",
      "0    2493\n",
      "Name: count, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "# Primero veamos la distribución actual y estadísticas de price\n",
    "print(\"Estadísticas de price:\")\n",
    "print(df['price'].describe())\n",
    "\n",
    "# Mostramos los percentiles para entender mejor la distribución\n",
    "print(\"\\nPercentiles de price:\")\n",
    "percentiles = [25, 50, 75]\n",
    "for p in percentiles:\n",
    "    print(f\"Percentil {p}: ${df['price'].quantile(p/100):.2f}\")\n",
    "\n",
    "# Usamos la mediana como punto de corte\n",
    "umbral = df['price'].median()\n",
    "print(f\"\\nUsando umbral de ${umbral:.2f} (mediana)\")\n",
    "\n",
    "# Convertimos a binario\n",
    "df['price_binary'] = (df['price'] >= umbral).astype(int)\n",
    "\n",
    "# Verificamos la conversión\n",
    "print(\"\\nValores únicos en price_binary:\", np.unique(df['price_binary']))\n",
    "print(\"\\nDistribución de price_binary:\")\n",
    "print(df['price_binary'].value_counts())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Distribución de clases antes del balanceo:\n",
      "price_binary\n",
      "1    2270\n",
      "0    1736\n",
      "Name: count, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "# Preparamos los datos para el modelo de regresión logística\n",
    "Vars_Indep = df[['room_type_encoded', 'accommodates', 'bathrooms', 'bedrooms', 'review_scores_rating']]\n",
    "Var_Dep = df['price_binary']\n",
    "\n",
    "# Manejamos los valores nulos en las variables independientes\n",
    "Vars_Indep = Vars_Indep.fillna(Vars_Indep.mean())\n",
    "\n",
    "# Redefinimos las variables\n",
    "X = Vars_Indep\n",
    "y = Var_Dep\n",
    "\n",
    "# Dividimos el conjunto de datos\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=42)\n",
    "\n",
    "# Mostramos la distribución original\n",
    "print(\"Distribución de clases antes del balanceo:\")\n",
    "print(pd.Series(y_train).value_counts())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Distribución de clases después del balanceo:\n",
      "price_binary\n",
      "1    2270\n",
      "0    2270\n",
      "Name: count, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "# Aplicamos SMOTE para balancear las clases\n",
    "smote = SMOTE(random_state=42)\n",
    "X_train_balanced, y_train_balanced = smote.fit_resample(X_train, y_train)\n",
    "\n",
    "# Verificamos la distribución después del balanceo\n",
    "print(\"\\nDistribución de clases después del balanceo:\")\n",
    "print(pd.Series(y_train_balanced).value_counts())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Distribución de las predicciones:\n",
      "0    976\n",
      "1    741\n",
      "Name: count, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "# Escalamos los datos\n",
    "escalar = StandardScaler()\n",
    "X_train_balanced = escalar.fit_transform(X_train_balanced)\n",
    "X_test = escalar.transform(X_test)\n",
    "\n",
    "# Entrenamos el modelo\n",
    "algoritmo = LogisticRegression()\n",
    "algoritmo.fit(X_train_balanced, y_train_balanced)\n",
    "\n",
    "# Realizamos predicciones\n",
    "y_pred = algoritmo.predict(X_test)\n",
    "\n",
    "# Mostramos la distribución de las predicciones\n",
    "print(\"Distribución de las predicciones:\")\n",
    "print(pd.Series(y_pred).value_counts())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Matriz de Confusión:\n",
      "[[654 103]\n",
      " [322 638]]\n",
      "\n",
      "Precisión para precio alto (1): 0.8609986504723347\n",
      "Precisión para precio bajo (0): 0.6700819672131147\n",
      "\n",
      "Sensibilidad para precio alto (1): 0.6645833333333333\n",
      "Sensibilidad para precio bajo (0): 0.8639365918097754\n",
      "\n",
      "Exactitud del modelo: 0.7524752475247525\n",
      "\n",
      "Puntaje F1: 0.7501469723691946\n"
     ]
    }
   ],
   "source": [
    "# Evaluación del modelo\n",
    "# Matriz de confusión\n",
    "matriz = confusion_matrix(y_test, y_pred)\n",
    "print('Matriz de Confusión:')\n",
    "print(matriz)\n",
    "\n",
    "# Precisión\n",
    "precision_pos = precision_score(y_test, y_pred, pos_label=1)\n",
    "precision_neg = precision_score(y_test, y_pred, pos_label=0)\n",
    "print('\\nPrecisión para precio alto (1):', precision_pos)\n",
    "print('Precisión para precio bajo (0):', precision_neg)\n",
    "\n",
    "# Sensibilidad (Recall)\n",
    "recall_pos = recall_score(y_test, y_pred, pos_label=1)\n",
    "recall_neg = recall_score(y_test, y_pred, pos_label=0)\n",
    "print('\\nSensibilidad para precio alto (1):', recall_pos)\n",
    "print('Sensibilidad para precio bajo (0):', recall_neg)\n",
    "\n",
    "# Exactitud\n",
    "exactitud = accuracy_score(y_test, y_pred)\n",
    "print('\\nExactitud del modelo:', exactitud)\n",
    "\n",
    "# F1 Score\n",
    "f1 = f1_score(y_test, y_pred, pos_label=1)\n",
    "print('\\nPuntaje F1:', f1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Convertir review_scores_rating en variable dicotómica\n",
    "\n",
    "Vamos a convertir la variable review_scores_rating en una variable dicotómica usando un umbral de 4.5:\n",
    "* 1 = Calificación alta (≥ 4.5)\n",
    "* 0 = Calificación baja (< 4.5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 160,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Estadísticas de review_scores_rating:\n",
      "count    5723.000000\n",
      "mean        4.816663\n",
      "std         0.156250\n",
      "min         4.300000\n",
      "25%         4.700000\n",
      "50%         4.820000\n",
      "75%         4.970000\n",
      "max         5.000000\n",
      "Name: review_scores_rating, dtype: float64\n",
      "\n",
      "Percentiles de review_scores_rating:\n",
      "Percentil 25: 4.70\n",
      "Percentil 50: 4.82\n",
      "Percentil 75: 4.97\n",
      "Percentil 90: 5.00\n",
      "\n",
      "Usando umbral de 4.5\n",
      "\n",
      "Valores únicos en rating_binary: [0 1]\n",
      "\n",
      "Distribución de rating_binary:\n",
      "rating_binary\n",
      "1    5539\n",
      "0     184\n",
      "Name: count, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "# Primero veamos la distribución actual y estadísticas\n",
    "print(\"Estadísticas de review_scores_rating:\")\n",
    "print(df['review_scores_rating'].describe())\n",
    "\n",
    "# Mostramos los percentiles para entender mejor la distribución\n",
    "print(\"\\nPercentiles de review_scores_rating:\")\n",
    "percentiles = [25, 50, 75, 90]\n",
    "for p in percentiles:\n",
    "    print(f\"Percentil {p}: {df['review_scores_rating'].quantile(p/100):.2f}\")\n",
    "\n",
    "# Convertimos a binario usando 4.5 como umbral (calificaciones de 4.5 o más son consideradas altas)\n",
    "umbral = 4.5\n",
    "print(f\"\\nUsando umbral de {umbral:.1f}\")\n",
    "\n",
    "# Convertimos a binario\n",
    "df['rating_binary'] = (df['review_scores_rating'] >= umbral).astype(int)\n",
    "\n",
    "# Verificamos la conversión\n",
    "print(\"\\nValores únicos en rating_binary:\", np.unique(df['rating_binary']))\n",
    "print(\"\\nDistribución de rating_binary:\")\n",
    "print(df['rating_binary'].value_counts())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 161,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Distribución de clases antes del balanceo:\n",
      "rating_binary\n",
      "1    3874\n",
      "0     132\n",
      "Name: count, dtype: int64\n",
      "\n",
      "Distribución de clases después de SMOTE:\n",
      "rating_binary\n",
      "1    3874\n",
      "0    3874\n",
      "Name: count, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "# Preparamos los datos para el modelo de regresión logística\n",
    "Vars_Indep = df[['room_type_encoded', 'accommodates', 'bathrooms', 'bedrooms', 'price']]\n",
    "Var_Dep = df['rating_binary']\n",
    "\n",
    "# Manejamos los valores nulos en las variables independientes\n",
    "Vars_Indep = Vars_Indep.fillna(Vars_Indep.mean())\n",
    "\n",
    "# Redefinimos las variables\n",
    "X = Vars_Indep\n",
    "y = Var_Dep\n",
    "\n",
    "# Dividimos el conjunto de datos\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=42)\n",
    "\n",
    "# Aplicamos SMOTE para balancear las clases\n",
    "smote = SMOTE(random_state=42)\n",
    "X_train_balanced, y_train_balanced = smote.fit_resample(X_train, y_train)\n",
    "\n",
    "# Mostramos la distribución original y después de SMOTE\n",
    "print(\"Distribución de clases antes del balanceo:\")\n",
    "print(pd.Series(y_train).value_counts())\n",
    "print(\"\\nDistribución de clases después de SMOTE:\")\n",
    "print(pd.Series(y_train_balanced).value_counts())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 162,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Distribución de las predicciones:\n",
      "0    910\n",
      "1    807\n",
      "Name: count, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "# Escalamos los datos\n",
    "escalar = StandardScaler()\n",
    "X_train_balanced = escalar.fit_transform(X_train_balanced)\n",
    "X_test = escalar.transform(X_test)\n",
    "\n",
    "# Entrenamos el modelo\n",
    "algoritmo = LogisticRegression()\n",
    "algoritmo.fit(X_train_balanced, y_train_balanced)\n",
    "\n",
    "# Realizamos predicciones\n",
    "y_pred = algoritmo.predict(X_test)\n",
    "\n",
    "# Mostramos la distribución de las predicciones\n",
    "print(\"Distribución de las predicciones:\")\n",
    "print(pd.Series(y_pred).value_counts())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 163,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Matriz de Confusión:\n",
      "[[ 37  15]\n",
      " [873 792]]\n",
      "\n",
      "Precisión para calificación alta (1): 0.9814126394052045\n",
      "Precisión para calificación baja (0): 0.04065934065934066\n",
      "\n",
      "Sensibilidad para calificación alta (1): 0.4756756756756757\n",
      "Sensibilidad para calificación baja (0): 0.7115384615384616\n",
      "\n",
      "Exactitud del modelo: 0.48281887012230634\n",
      "\n",
      "Puntaje F1: 0.6407766990291263\n"
     ]
    }
   ],
   "source": [
    "# Evaluación del modelo\n",
    "# Matriz de confusión\n",
    "matriz = confusion_matrix(y_test, y_pred)\n",
    "print('Matriz de Confusión:')\n",
    "print(matriz)\n",
    "\n",
    "# Precisión\n",
    "precision_pos = precision_score(y_test, y_pred, pos_label=1)\n",
    "precision_neg = precision_score(y_test, y_pred, pos_label=0)\n",
    "print('\\nPrecisión para calificación alta (1):', precision_pos)\n",
    "print('Precisión para calificación baja (0):', precision_neg)\n",
    "\n",
    "# Sensibilidad (Recall)\n",
    "recall_pos = recall_score(y_test, y_pred, pos_label=1)\n",
    "recall_neg = recall_score(y_test, y_pred, pos_label=0)\n",
    "print('\\nSensibilidad para calificación alta (1):', recall_pos)\n",
    "print('Sensibilidad para calificación baja (0):', recall_neg)\n",
    "\n",
    "# Exactitud\n",
    "exactitud = accuracy_score(y_test, y_pred)\n",
    "print('\\nExactitud del modelo:', exactitud)\n",
    "\n",
    "# F1 Score\n",
    "f1 = f1_score(y_test, y_pred, pos_label=1)\n",
    "print('\\nPuntaje F1:', f1)"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "authorship_tag": "ABX9TyNKtew5CuhPLFGDGfhs25px",
   "include_colab_link": true,
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
